{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from collections import Counter\r\n",
    "from datetime import datetime, timedelta as td\r\n",
    "import math\r\n",
    "from matplotlib import gridspec, pyplot as plt, rc, ticker\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "from scipy.stats import poisson\r\n",
    "import sys\r\n",
    "\r\n",
    "dtf = datetime.strftime\r\n",
    "dtp = datetime.strptime\r\n",
    "\r\n",
    "plt.style.use(['science','ieee'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class ExpLogHandler:\r\n",
    "    \"\"\"Class to find, combine, and pre-process all required data files.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        log_names (list): List of names of required log files.\r\n",
    "\r\n",
    "    Attributes:\r\n",
    "        log_names (list): Where log_names is stored.\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, log_names):\r\n",
    "        \"\"\"Initialiser for the ExpLogHandler class.\r\n",
    "\r\n",
    "        Args:\r\n",
    "            log_names (list): List of names of required log files.\r\n",
    "        \"\"\"\r\n",
    "        self.log_names = log_names\r\n",
    "        \r\n",
    "    def getData(self):\r\n",
    "        \"\"\"Acquire data files, combine, remove duplicate column headers, join indices\r\n",
    "\r\n",
    "        Args:\r\n",
    "            None\r\n",
    "        \r\n",
    "        Returns:\r\n",
    "            data: Complete DataFrame of all experiment log lines.\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        self.data = pd.read_csv(self.log_names[0], on_bad_lines=\"skip\", dtype={'SDC_val': str})\r\n",
    "        for i in range(1, len(self.log_names)):\r\n",
    "            data_next   = pd.read_csv(self.log_names[i], on_bad_lines=\"skip\", dtype={'SDC_val': str})\r\n",
    "            data_frames = [self.data, data_next]\r\n",
    "            self.data   = pd.concat(data_frames, ignore_index=True)\r\n",
    "        self.data.drop(self.data.loc[(self.data[\"Timestamp\"] == \"Timestamp\")].index.tolist())\r\n",
    "        self.dataLength = self.data.shape[0]\r\n",
    "\r\n",
    "        wrchckbrdLocs  = self.data.loc[(self.data[\"Board\"] == \"M\") & (self.data[\"Mikroe_socket\"] == \"A\") &\r\n",
    "                                       (self.data[\"Status\"] == \"WRCHCKBRD\")].index.tolist()\r\n",
    "        wrchckbrdIndex = [(i, \"WRCHCKBRD\") for i in wrchckbrdLocs]\r\n",
    "        initLocs       = self.data.loc[(self.data[\"Board\"] == \"M\") & (self.data[\"Mikroe_socket\"] == \"A\") &\r\n",
    "                         (self.data[\"Status\"] == \"INIT\")].index.tolist()\r\n",
    "        initIndex      = [(i, \"INIT\") for i in initLocs]\r\n",
    "        runIndex       = wrchckbrdIndex + initIndex\r\n",
    "        runIndex       = sorted(runIndex)\r\n",
    "        runIndex.append((self.dataLength, \"END\"))\r\n",
    "\r\n",
    "        runId  = 1\r\n",
    "        runCol = [''] * self.dataLength\r\n",
    "        for h in range(len(runIndex) - 1):\r\n",
    "            if runIndex[h][1] == \"WRCHCKBRD\":\r\n",
    "                start              = runIndex[h][0]\r\n",
    "                end                = runIndex[h+1][0]\r\n",
    "                runCol[start:end]  = [runId]*(end-start)\r\n",
    "                runId              += 1\r\n",
    "\r\n",
    "        self.data.insert(loc=0, column=\"Run_ID\", value=runCol)\r\n",
    "        return self.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class BeamLogHandler:\r\n",
    "    \"\"\"Class to retrieve all neutron logs for experiment dates.\r\n",
    "\r\n",
    "    Attributes:\r\n",
    "        beamLogFnameFormat (str): Datetime format for beamlog file names.\r\n",
    "        firstTime (datetime): Datetime object of first experiment timestamp.\r\n",
    "        lastTime (datetime): Datetime object of last experiment timestamp.\r\n",
    "        targetDir_fullpathList (list): List of each parent directory of experiment results directory.\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, firstTime, lastTime, targetDir_fullpathList):     \r\n",
    "        self.beamLogFnameFormat          = \"%Y-%m-%d\"\r\n",
    "        self.firstTime                   = firstTime\r\n",
    "        self.lastTime                    = lastTime\r\n",
    "        self.targetDir_fullpathList      = targetDir_fullpathList\r\n",
    "        self.targetDir_fullpathList[-4:] = [\"neutrons\"]\r\n",
    "\r\n",
    "    def getLogs(self):\r\n",
    "        firstBeamTime = dtf(self.firstTime, self.beamLogFnameFormat)\r\n",
    "        beamlogDayDif = (self.lastTime - self.firstTime).days\r\n",
    "        beamPath      = \"../../../neutrons/countlog-\"\r\n",
    "        self.beamlog  = pd.read_csv(f\"{beamPath}{firstBeamTime}.txt\",\r\n",
    "                        delim_whitespace=True, header=None, skiprows=1)\r\n",
    "        nextTime      = self.firstTime\r\n",
    "        for i in range(0, beamlogDayDif+1):\r\n",
    "            nextTime      = nextTime + td(days=1)\r\n",
    "            nextBeamTime  = dtf(nextTime, self.beamLogFnameFormat)\r\n",
    "            try:\r\n",
    "                nextBeamlog   = pd.read_csv(f\"{beamPath}{nextBeamTime}.txt\",delim_whitespace=True,header=None,skiprows=1)\r\n",
    "            except FileNotFoundError:\r\n",
    "                pass\r\n",
    "            beamlogFrames = [self.beamlog, nextBeamlog]\r\n",
    "            self.beamlog  = pd.concat(beamlogFrames, ignore_index=True)\r\n",
    "            \r\n",
    "        self.beamlog.columns = [\"Date\",\"HMS_time\",\"Millisecs\",\"Count1\",\"Count2\",\r\n",
    "                                \"Count3\",\"Count4\",\"protonCharge\",\"Beam_current\"]\r\n",
    "        return self.beamlog"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Run:\r\n",
    "    \"\"\"Class for one repetition of an experiment.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        num (int): Run number for the selected experiment logs.\r\n",
    "        runData (DataFrame): Truncated DataFrame of log lines for the run.\r\n",
    "    \r\n",
    "    Attributes:\r\n",
    "        delay (int): Length in milliseconds of beam 'bathing time'.\r\n",
    "        df (DataFrame): Saving runData.\r\n",
    "        errors (int): Number of nvRAM errors.\r\n",
    "        fullErr (int): 1 if the entire nvRAM array was errored.\r\n",
    "        hot (int): 1 if the beam was on, 0 if not.\r\n",
    "        num (int): Saving num.\r\n",
    "        rowErr (int): 1 if there was at least one row error.\r\n",
    "        see (int): Number of true SEEs detected.\r\n",
    "        valid (int): 1 if the run had all expected log lines, 0 if not.\r\n",
    "        _ErrorsNVRAM (list): List of tuples (error_byte, error_location) for each chip.\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, num, runData):\r\n",
    "        \"\"\"Initialiser for the Run class. \r\n",
    "\r\n",
    "        Parameters:\r\n",
    "            num (int): Run number for the selected experiment logs.\r\n",
    "            runData (DataFrame): Truncated DataFrame of log lines for the run.\r\n",
    "        \"\"\"\r\n",
    "        self.delay     = -1\r\n",
    "        self.df        = runData\r\n",
    "        self.errors    = 0\r\n",
    "        self.fullErr   = -1\r\n",
    "        self.hot       = -1\r\n",
    "        self.num       = num\r\n",
    "        self.rowErr    = -1\r\n",
    "        self.see       = -1\r\n",
    "        self.valid     = -1\r\n",
    "        self.aErrNVRAM = []\r\n",
    "        self.bErrNVRAM = []\r\n",
    "        self.cErrNVRAM = []\r\n",
    "        self.dErrNVRAM = []\r\n",
    "        self.aErrorBounds = []\r\n",
    "        self.bErrorBounds = []\r\n",
    "        self.cErrorBounds = []\r\n",
    "        self.dErrorBounds = []\r\n",
    "        self.aErrNVRAMVals = []\r\n",
    "        self.bErrNVRAMVals = []\r\n",
    "        self.cErrNVRAMVals = []\r\n",
    "        self.dErrNVRAMVals = []\r\n",
    "        self.aErrNVRAMLocs = []\r\n",
    "        self.bErrNVRAMLocs = []\r\n",
    "        self.cErrNVRAMLocs = []\r\n",
    "        self.dErrNVRAMLocs = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Analyser:\r\n",
    "    '''\r\n",
    "    Class to handle processing data.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        targetDir_fullpath (string): File path of directory to analyse.\r\n",
    "\r\n",
    "    Attributes:\r\n",
    "        targetDir_fullpath (string): Storing targetDir_fullpath arg.\r\n",
    "        expLogTstampFormat (string): Datetime format for experiment log timestamps\r\n",
    "        beamLogTstampFormat (string): Datetime format for beam log timestamps                \r\n",
    "    '''\r\n",
    "    def __init__(self, targDir_full):\r\n",
    "        '''\r\n",
    "        Retrieve + store target directory, initialise datetime formats.\r\n",
    "\r\n",
    "        Args:\r\n",
    "            targetDir_fullpath (string): File path of directory to analyse.\r\n",
    "\r\n",
    "        Attributes:\r\n",
    "            ignores (string): Experiment run IDs to ignore during processing\r\n",
    "            targetDir_fullpath (string): Storing targetDir_fullpath arg.\r\n",
    "            expLogTstampFormat (string): Datetime format for experiment log timestamps\r\n",
    "            beamLogTstampFormat (string): Datetime format for beam log timestamps\r\n",
    "        '''\r\n",
    "        self.ignores = []\r\n",
    "        self.targDir_full = targDir_full\r\n",
    "        self.expLogTstampFormat  = \"%Y-%m-%d_%H-%M-%S-%f\"\r\n",
    "        self.beamLogTstampFormat = \"%d/%m/%Y %H:%M:%S\"\r\n",
    " \r\n",
    "    def setup(self):\r\n",
    "        #targetDir_fullpathList = self.targDir_full.split(\"/\")\r\n",
    "        targDir_fullList = self.targDir_full.split(\"/\")\r\n",
    "        targDir_trunc    = targDir_fullList[-4:-1]\r\n",
    "        self.chip        = targDir_trunc[0]\r\n",
    "        self.variant     = targDir_trunc[1]\r\n",
    "        self.size        = targDir_trunc[2]\r\n",
    "\r\n",
    "        # Get data from logs\r\n",
    "        self.log_names     = [self.targDir_full+i for i in os.listdir(self.targDir_full) if \".csv\" in i]\r\n",
    "        self.log_names.sort(key = lambda x: dtp(x, f\"{self.targDir_full}nvRAM_data_%d-%m-%Y-%H%M.csv\"))\r\n",
    "        self.ExpLogHandler = ExpLogHandler(self.log_names)\r\n",
    "        self.data          = self.ExpLogHandler.getData()\r\n",
    "\r\n",
    "        # Get beam status from logs\r\n",
    "        firstTimestamp      = self.data[0:1]['Timestamp'][0]\r\n",
    "        lastTimestamp       = self.data[self.data.shape[0]-2:self.data.shape[0]-1]['Timestamp'][self.data.shape[0]-2]\r\n",
    "        firstTime           = dtp(firstTimestamp, self.expLogTstampFormat)\r\n",
    "        lastTime            = dtp(lastTimestamp, self.expLogTstampFormat)\r\n",
    "        self.BeamLogHandler = BeamLogHandler(firstTime, lastTime, targDir_fullList)\r\n",
    "        self.beamlog        = self.BeamLogHandler.getLogs()\r\n",
    "\r\n",
    "        # Create datetime objects from beamlog timestamps\r\n",
    "        beamlogTstamps    = (self.beamlog['Date']+self.beamlog['HMS_time']+self.beamlog['Millisecs'].apply(str)).tolist()\r\n",
    "        self.beamlogTimes = []\r\n",
    "        for i in beamlogTstamps:\r\n",
    "            if len(i) > 23:\r\n",
    "                i = i[0:26]\r\n",
    "            self.beamlogTimes.append(i)\r\n",
    "        self.beamlogTimes = [dtp(i, '%d/%m/%Y%H:%M:%S0.%f') for i in self.beamlogTimes]\r\n",
    "\r\n",
    "    def beamOn(self, firstTstamp, lastTstamp):\r\n",
    "        bOfirstTime = firstTstamp\r\n",
    "        bOlastTime = lastTstamp\r\n",
    "        beamTimeNearFirstTime = min([i for i in self.beamlogTimes if i <= bOfirstTime], key=lambda x: abs(x - bOfirstTime))\r\n",
    "        beamTimeNearLastTime  = min([i for i in self.beamlogTimes if i >= bOlastTime], key=lambda x: abs(x - bOlastTime))\r\n",
    "        firstRow              = self.beamlog.loc[(self.beamlog['Date'] == dtf(beamTimeNearFirstTime, '%d/%m/%Y')) &\r\n",
    "                                (self.beamlog['HMS_time'] == dtf(beamTimeNearFirstTime, '%H:%M:%S'))]\r\n",
    "        lastRow               = self.beamlog.loc[(self.beamlog['Date'] == dtf(beamTimeNearLastTime, '%d/%m/%Y')) & \r\n",
    "                                (self.beamlog['HMS_time'] == dtf(beamTimeNearLastTime, '%H:%M:%S'))]\r\n",
    "        count4Dif             = lastRow.iloc[0]['Count4'] - firstRow.iloc[0]['Count4']\r\n",
    "        numRows               = lastRow.index.astype(int)[0] - firstRow.index.astype(int)[0]\r\n",
    "        cps                   = count4Dif / numRows\r\n",
    "        if cps > 1:\r\n",
    "            return 1\r\n",
    "        return 0\r\n",
    "\r\n",
    "    def createRuns(self):\r\n",
    "        runNames  = []\r\n",
    "        self.runs = {}\r\n",
    "        lastRunID =  self.data[self.data['Run_ID'].last_valid_index():self.data['Run_ID'].\r\n",
    "                     last_valid_index()+1]['Run_ID'][self.data['Run_ID'].last_valid_index()]\r\n",
    "\r\n",
    "        # Supply Run initialiser with truncated data \r\n",
    "        for i in range(1, lastRunID + 1):\r\n",
    "            runNames.append(f\"run_{i}\")\r\n",
    "            runData      = self.data.loc[(self.data[\"Run_ID\"] == i)]\r\n",
    "            runData.reset_index(inplace=True, drop=True)\r\n",
    "            self.runs[i] = Run(i, runData)\r\n",
    "\r\n",
    "        # TODO: Add logic for single-chip runs, currently only supporting half experiment runs.\r\n",
    "\r\n",
    "        for run in self.runs.values():\r\n",
    "            if self.variant == \"1\":\r\n",
    "                    try:\r\n",
    "                        # Extract beam delay from timestamps\r\n",
    "                        before_delay_i  = run.df.loc[(run.df['Mikroe_socket']=='D') & (run.df['Status']=='STORE_OK')].index[0]\r\n",
    "                        before_delay_t  = run.df.loc[before_delay_i]['Timestamp']\r\n",
    "                        after_delay_i   = run.df.loc[(run.df['Mikroe_socket']=='A') & (run.df['Status']=='VERIF')].index[0] + 1\r\n",
    "                        after_delay_t   = run.df.loc[after_delay_i]['Timestamp']\r\n",
    "                        before_delay_dt = dtp(before_delay_t, self.expLogTstampFormat)\r\n",
    "                        after_delay_dt  = dtp(after_delay_t, self.expLogTstampFormat)   \r\n",
    "                        dif             = after_delay_dt - before_delay_dt\r\n",
    "                        \r\n",
    "                        if dif < td(seconds = 0.5):\r\n",
    "                            run.delay = 0.1\r\n",
    "                        if td(seconds = 0.5) < dif < td(seconds = 5):\r\n",
    "                            run.delay = 1\r\n",
    "                        if td(seconds = 5)   < dif < td(seconds = 50):\r\n",
    "                            run.delay = 10\r\n",
    "                        if td(seconds = 50)  < dif < td(seconds = 500):\r\n",
    "                            run.delay = 100\r\n",
    "                        if td(seconds = 500) < dif < td(seconds = 5000):\r\n",
    "                            run.delay = 1000\r\n",
    "\r\n",
    "                        # Was the beam on?\r\n",
    "                        try:\r\n",
    "                            if self.beamOn(before_delay_dt, after_delay_dt):\r\n",
    "                                run.hot = 1\r\n",
    "                            else:\r\n",
    "                                run.hot = 0\r\n",
    "                        except ValueError:\r\n",
    "                            print(run.name)\r\n",
    "\r\n",
    "                        # Create list of errors in nvRAM per chip\r\n",
    "                        aErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                                run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                        bErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                                run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") &\r\n",
    "                                            (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                        cErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                                run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                        dErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                                run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                        aErrorsBefRec = list(zip(run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                        aErrorsAftRec = list(zip(run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                        bErrorsBefRec = list(zip(run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                        bErrorsAftRec = list(zip(run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                        cErrorsBefRec = list(zip(run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                        cErrorsAftRec = list(zip(run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                        dErrorsBefRec = list(zip(run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                        dErrorsAftRec = list(zip(run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_loc\"].values.tolist())) \r\n",
    "                        \r\n",
    "                        run.aErrNVRAM = [i for i in bErrorsAftRec if i not in bErrorsBefRec if np.nan not in i]\r\n",
    "                        run.bErrNVRAM = [i for i in bErrorsAftRec if i not in bErrorsBefRec if np.nan not in i]\r\n",
    "                        run.cErrNVRAM = [i for i in cErrorsAftRec if i not in cErrorsBefRec if np.nan not in i]\r\n",
    "                        run.dErrNVRAM = [i for i in dErrorsAftRec if i not in dErrorsBefRec if np.nan not in i]\r\n",
    "\r\n",
    "                        run.errors += len(run.aErrNVRAM)\r\n",
    "                        run.errors += len(run.bErrNVRAM)\r\n",
    "                        run.errors += len(run.cErrNVRAM)\r\n",
    "                        run.errors += len(run.dErrNVRAM)\r\n",
    "\r\n",
    "                    except IndexError:\r\n",
    "                        run.valid = 0\r\n",
    "                    else:\r\n",
    "                        run.valid = 1\r\n",
    "                        \r\n",
    "            if self.variant == \"2\":\r\n",
    "                try:\r\n",
    "                    # Extract beam delay from timestamps\r\n",
    "                    before_delay_i  = run.df.loc[(run.df['Mikroe_socket']=='D') & (run.df['Status']=='STORE_OK')].index[0]\r\n",
    "                    before_delay_t  = run.df.loc[before_delay_i]['Timestamp']\r\n",
    "                    after_delay_i   = run.df.loc[(run.df['Mikroe_socket']=='A') & (run.df['Status']=='VERIF')].index[0] + 1\r\n",
    "                    after_delay_t   = run.df.loc[after_delay_i]['Timestamp']\r\n",
    "                    before_delay_dt = dtp(before_delay_t, self.expLogTstampFormat)\r\n",
    "                    after_delay_dt  = dtp(after_delay_t, self.expLogTstampFormat)   \r\n",
    "                    dif             = after_delay_dt - before_delay_dt\r\n",
    "                    \r\n",
    "                    if td(seconds = 0.1) < dif < td(seconds = 0.5):\r\n",
    "                        run.delay = 0.1\r\n",
    "                    if td(seconds = 0.5) < dif < td(seconds = 5):\r\n",
    "                        run.delay = 1\r\n",
    "                    if td(seconds = 5)   < dif < td(seconds = 50):\r\n",
    "                        run.delay = 10\r\n",
    "                    if td(seconds = 50)  < dif < td(seconds = 500):\r\n",
    "                        run.delay = 100\r\n",
    "                    if td(seconds = 500) < dif < td(seconds = 5000):\r\n",
    "                        run.delay = 1000\r\n",
    "\r\n",
    "                    # Was the beam on?\r\n",
    "                    try:\r\n",
    "                        if self.beamOn(before_delay_dt, after_delay_dt):\r\n",
    "                            run.hot = 1\r\n",
    "                        else:\r\n",
    "                            run.hot = 0\r\n",
    "                    except ValueError:\r\n",
    "                        print(run.name)\r\n",
    "                        \r\n",
    "                    # Create list of errors in nvRAM per chip\r\n",
    "                    aErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                            run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                    bErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                            run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") &\r\n",
    "                                        (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                    cErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                            run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                    dErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                            run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                    aErrBefDelay = list(zip(run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    aErrBefRec = list(zip(run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    aErrAftRec = list(zip(run.df[aErrorBounds[2][0]+1:aErrorBounds[2][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[aErrorBounds[2][0]+1:aErrorBounds[2][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                    bErrBefDelay = list(zip(run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    bErrBefRec = list(zip(run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    bErrAftRec = list(zip(run.df[bErrorBounds[2][0]+1:bErrorBounds[2][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[bErrorBounds[2][0]+1:bErrorBounds[2][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    \r\n",
    "                    cErrBefDelay = list(zip(run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    cErrBefRec = list(zip(run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    cErrAftRec = list(zip(run.df[cErrorBounds[2][0]+1:cErrorBounds[2][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[cErrorBounds[2][0]+1:cErrorBounds[2][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    \r\n",
    "                    dErrBefDelay = list(zip(run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    dErrBefRec = list(zip(run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    dErrAftRec = list(zip(run.df[dErrorBounds[2][0]+1:dErrorBounds[2][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[dErrorBounds[2][0]+1:dErrorBounds[2][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    \r\n",
    "                    run.aErrNVRAM = [i for i in aErrAftRec if i not in aErrBefDelay if i not in aErrBefRec if np.nan not in i]\r\n",
    "                    run.bErrNVRAM = [i for i in bErrAftRec if i not in bErrBefDelay if i not in bErrBefRec if np.nan not in i]\r\n",
    "                    run.cErrNVRAM = [i for i in cErrAftRec if i not in cErrBefDelay if i not in cErrBefRec if np.nan not in i]\r\n",
    "                    run.dErrNVRAM = [i for i in dErrAftRec if i not in dErrBefDelay if i not in dErrBefRec if np.nan not in i]\r\n",
    "                    \r\n",
    "                    run.errors += len(run.aErrNVRAM)\r\n",
    "                    run.errors += len(run.bErrNVRAM)\r\n",
    "                    run.errors += len(run.cErrNVRAM)\r\n",
    "                    run.errors += len(run.dErrNVRAM)\r\n",
    "\r\n",
    "                # Invalidate run if critical experiment steps didn't occur\r\n",
    "                except IndexError:\r\n",
    "                    run.valid = 0\r\n",
    "                else:\r\n",
    "                    run.valid = 1\r\n",
    "\r\n",
    "\r\n",
    "    def diffFinder(self, variant):\r\n",
    "        '''Find runs with large patterns in error location.\r\n",
    "        '''\r\n",
    "        patterns = []\r\n",
    "        for run in variant.values():    \r\n",
    "            diffA = [int(run.aErrNVRAM[i+1][1], 16) - int(run.aErrNVRAM[i][1], 16) \r\n",
    "                            for i in range(0, len(run.aErrNVRAM)-1)]\r\n",
    "            diffB = [int(run.bErrNVRAM[i+1][1], 16) - int(run.bErrNVRAM[i][1], 16)\r\n",
    "                            for i in range(0, len(run.bErrNVRAM)-1)]\r\n",
    "            diffC = [int(run.cErrNVRAM[i+1][1], 16) - int(run.cErrNVRAM[i][1], 16)\r\n",
    "                            for i in range(0, len(run.cErrNVRAM)-1)]\r\n",
    "            diffD = [int(run.dErrNVRAM[i+1][1], 16) - int(run.dErrNVRAM[i][1], 16)\r\n",
    "                            for i in range(0, len(run.dErrNVRAM)-1)]\r\n",
    "\r\n",
    "            diffA2 = [abs(diffA[i+1] - diffA[i]) for i in range(0, len(diffA)-1)]\r\n",
    "            diffB2 = [abs(diffB[i+1] - diffB[i]) for i in range(0, len(diffB)-1)]\r\n",
    "            diffC2 = [abs(diffC[i+1] - diffC[i]) for i in range(0, len(diffC)-1)]\r\n",
    "            diffD2 = [abs(diffD[i+1] - diffD[i]) for i in range(0, len(diffD)-1)]\r\n",
    "\r\n",
    "            diffADict1 = {k: v for k, v in sorted(Counter(diffA).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffBDict1 = {k: v for k, v in sorted(Counter(diffB).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffCDict1 = {k: v for k, v in sorted(Counter(diffC).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffDDict1 = {k: v for k, v in sorted(Counter(diffD).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "\r\n",
    "            diffADict2 = {k: v for k, v in sorted(Counter(diffA2).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffBDict2 = {k: v for k, v in sorted(Counter(diffB2).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffCDict2 = {k: v for k, v in sorted(Counter(diffC2).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffDDict2 = {k: v for k, v in sorted(Counter(diffD2).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "\r\n",
    "            lastMemDigitA = [i[1][-1] for i in run.aErrNVRAM]\r\n",
    "            lastMemDigitB = [i[1][-1] for i in run.bErrNVRAM]\r\n",
    "            lastMemDigitC = [i[1][-1] for i in run.cErrNVRAM]\r\n",
    "            lastMemDigitD = [i[1][-1] for i in run.dErrNVRAM]\r\n",
    "\r\n",
    "            lmdADict = {k: v for k, v in sorted(Counter(lastMemDigitA).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            lmdBDict = {k: v for k, v in sorted(Counter(lastMemDigitB).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            lmdCDict = {k: v for k, v in sorted(Counter(lastMemDigitC).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            lmdDDict = {k: v for k, v in sorted(Counter(lastMemDigitD).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "\r\n",
    "            if diffADict2:\r\n",
    "                tot_err = len(run.aErrNVRAM)\r\n",
    "                if list(diffADict2.items())[:1][0][1] >= 5:\r\n",
    "                    if (list(diffADict2.items())[:1][0][1] / tot_err) > 0.1:\r\n",
    "                        patterns.append(run.num)\r\n",
    "\r\n",
    "            if diffBDict2:\r\n",
    "                tot_err = len(run.bErrNVRAM)\r\n",
    "                if list(diffBDict2.items())[:1][0][1] >= 5:\r\n",
    "                    if (list(diffBDict2.items())[:1][0][1] / tot_err) > 0.1:\r\n",
    "                        patterns.append(run.num)\r\n",
    "            \r\n",
    "            if diffCDict2:\r\n",
    "                tot_err = len(run.cErrNVRAM)\r\n",
    "                if list(diffCDict2.items())[:1][0][1] >= 5:\r\n",
    "                    if (list(diffCDict2.items())[:1][0][1] / tot_err) > 0.1:\r\n",
    "                        patterns.append(run.num)\r\n",
    "\r\n",
    "            if diffDDict2:\r\n",
    "                tot_err = len(run.dErrNVRAM)\r\n",
    "                if list(diffDDict2.items())[:1][0][1] >= 5:\r\n",
    "                    if (list(diffDDict2.items())[:1][0][1] / tot_err) > 0.1:\r\n",
    "                        patterns.append(run.num)\r\n",
    "                        \r\n",
    "            else:\r\n",
    "                if lmdADict:\r\n",
    "                    if list(lmdADict.items())[:1][0][1] >= 5:\r\n",
    "                        tot_err = len(run.aErrNVRAM)\r\n",
    "                        if (list(lmdADict.items())[:1][0][1] / tot_err) > 0.75:\r\n",
    "                            patterns.append(run.num)\r\n",
    "\r\n",
    "                if lmdBDict:\r\n",
    "                    if list(lmdBDict.items())[:1][0][1] >= 5:\r\n",
    "                        tot_err = len(run.bErrNVRAM)\r\n",
    "                        if (list(lmdBDict.items())[:1][0][1] / tot_err) > 0.75:\r\n",
    "                            patterns.append(run.num)\r\n",
    "\r\n",
    "                if lmdCDict:\r\n",
    "                    if list(lmdCDict.items())[:1][0][1] >= 5:\r\n",
    "                        tot_err = len(run.cErrNVRAM)\r\n",
    "                        if (list(lmdCDict.items())[:1][0][1] / tot_err) > 0.75:\r\n",
    "                            patterns.append(run.num)\r\n",
    "\r\n",
    "                if lmdDDict:\r\n",
    "                    if list(lmdDDict.items())[:1][0][1] >= 5:\r\n",
    "                        tot_err = len(run.dErrNVRAM)\r\n",
    "                        if (list(lmdDDict.items())[:1][0][1] / tot_err) > 0.75:\r\n",
    "                            patterns.append(run.num)\r\n",
    "                else:\r\n",
    "                    continue\r\n",
    "\r\n",
    "        return sorted(list(set(patterns)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "sram3_1_single   = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/SRAM3/1/single/\")\r\n",
    "sram3_1_single.setup()\r\n",
    "sram3_1_single.createRuns()\r\n",
    "sram3_1_single.ignores = sram3_1_single.diffFinder(sram3_1_single.runs)\r\n",
    "print(\"sram3_1_single ready\")\r\n",
    "\r\n",
    "sram3_1_half     = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/SRAM3/1/half/\")\r\n",
    "sram3_1_half.setup()\r\n",
    "sram3_1_half.createRuns()\r\n",
    "sram3_1_half.ignores = sram3_1_half.diffFinder(sram3_1_half.runs)\r\n",
    "more_ignores = [8,10,12,14,17,21,22,23,24,25,26,362,363,370,371,372,375,376,377,378,381,382,385,386,387,388,389,392,397,398,\r\n",
    "                400,401,404,406,407,408,414,415,416,417,418,430,431,432,433,434,1542,1613]\r\n",
    "sram3_1_half.ignores.extend(more_ignores)\r\n",
    "print(\"sram3_1_half ready\")\r\n",
    "\r\n",
    "sram3_2_half     = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/SRAM3/2/half/\")\r\n",
    "sram3_2_half.setup()\r\n",
    "sram3_2_half.createRuns()\r\n",
    "sram3_2_half.ignores = sram3_2_half.diffFinder(sram3_2_half.runs)\r\n",
    "print(\"sram3_2_half ready\")\r\n",
    "\r\n",
    "nvsram2_1_single = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/nvSRAM2/1/single/\")\r\n",
    "nvsram2_1_single.setup()\r\n",
    "nvsram2_1_single.createRuns()\r\n",
    "nvsram2_1_single.ignores = nvsram2_1_single.diffFinder(nvsram2_1_single.runs)\r\n",
    "print(\"nvsram2_1_single ready\")\r\n",
    "\r\n",
    "nvsram2_1_half   = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/nvSRAM2/1/half/\")\r\n",
    "nvsram2_1_half.setup()\r\n",
    "nvsram2_1_half.createRuns()\r\n",
    "nvsram2_1_half.ignores = nvsram2_1_half.diffFinder(nvsram2_1_half.runs)\r\n",
    "print(\"nvsram2_1_half ready\")\r\n",
    "\r\n",
    "nvsram2_2_half   = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/nvSRAM2/2/half/\")\r\n",
    "nvsram2_2_half.setup()\r\n",
    "nvsram2_2_half.createRuns()\r\n",
    "nvsram2_2_half.ignores = nvsram2_2_half.diffFinder(nvsram2_2_half.runs)\r\n",
    "print(\"nvsram2_2_half ready\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sram3_1_single ready\n",
      "sram3_1_half ready\n",
      "sram3_2_half ready\n",
      "nvsram2_1_single ready\n",
      "nvsram2_1_half ready\n",
      "nvsram2_2_half ready\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "sram3_1_single_runs_ranked = []\r\n",
    "sram3_1_half_runs_ranked   = []\r\n",
    "sram3_2_half_ranked        = []\r\n",
    "nvsram2_1_single_ranked    = []\r\n",
    "nvsram2_1_half_ranked      = []\r\n",
    "nvsram2_2_half_ranked      = []\r\n",
    "\r\n",
    "for run in sram3_1_single.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        sram3_1_single_runs_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        sram3_1_half_runs_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in sram3_2_half.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        sram3_2_half_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in nvsram2_1_single.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        nvsram2_1_single_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in nvsram2_1_half.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        nvsram2_1_half_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in nvsram2_2_half.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        nvsram2_2_half_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "sram3_1_single_runs_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "sram3_1_half_runs_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "sram3_2_half_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "nvsram2_1_single_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "nvsram2_1_half_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "nvsram2_2_half_ranked.sort(reverse=True, key=lambda i: i[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the number of flipped bits per neutron event across the current data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "goldbyte = 170\r\n",
    "\r\n",
    "def hamDistFinder(error, goldbyte):\r\n",
    "    return bin(int(error[0], 16) ^ goldbyte).count('1')\r\n",
    "\r\n",
    "hamDistList_sub1 = []\r\n",
    "hamDistDict_sub1 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 0.1:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_sub1.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_sub1.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_sub1.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_sub1.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_sub1.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_sub1 = Counter(hamDistList_sub1)\r\n",
    "counts_sub1 = list(hamDistDict_sub1.values())\r\n",
    "tot_err_sub1 = sum(counts_sub1)\r\n",
    "x_sub1 = [0,1,2,3]\r\n",
    "lmbda_sub1 = 0.27\r\n",
    "poisson_sub1 = poisson.pmf(x_sub1, lmbda_sub1)\r\n",
    "errors_sub1 = [(math.sqrt(counts_sub1[0])), (math.sqrt(counts_sub1[1])),\r\n",
    "               (math.sqrt(counts_sub1[2]))]\r\n",
    "\r\n",
    "hamDistList_1 = []\r\n",
    "hamDistDict_1 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 1:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_1.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_1.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_1.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_1.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_1.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_1 = Counter(hamDistList_1)\r\n",
    "counts_1 = list(hamDistDict_1.values())\r\n",
    "tot_err_1 = sum(counts_1)\r\n",
    "x_1 = [0,1,2,3]\r\n",
    "lmbda_1 = 0.279\r\n",
    "poisson_1 = poisson.pmf(x_1, lmbda_1)\r\n",
    "errors_1 = [(math.sqrt(counts_1[0])), (math.sqrt(counts_1[1])),\r\n",
    "               (math.sqrt(counts_1[2]))]\r\n",
    "\r\n",
    "hamDistList_10 = []\r\n",
    "hamDistDict_10 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 10:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_10.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_10.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_10.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_10.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_10.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_10 = Counter(hamDistList_10)\r\n",
    "counts_10 = list(hamDistDict_10.values())\r\n",
    "tot_err_10 = sum(counts_10)\r\n",
    "x_10 = [0,1,2,3]\r\n",
    "lmbda_10 = 0.36\r\n",
    "poisson_10 = poisson.pmf(x_10, lmbda_10)\r\n",
    "errors_10 = [(math.sqrt(counts_10[0])), (math.sqrt(counts_10[1])),\r\n",
    "               (math.sqrt(counts_10[2]))]\r\n",
    "\r\n",
    "hamDistList_100 = []\r\n",
    "hamDistDict_100 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 100:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_100.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_100.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_100.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_100.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_100.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_100 = Counter(hamDistList_100)\r\n",
    "counts_100 = list(hamDistDict_100.values())\r\n",
    "tot_err_100 = sum(counts_100)\r\n",
    "x_100 = [0,1,2,3]\r\n",
    "lmbda_100 = 0.29\r\n",
    "poisson_100 = poisson.pmf(x_100, lmbda_100)\r\n",
    "errors_100 = [(math.sqrt(counts_100[0])), (math.sqrt(counts_100[1])),\r\n",
    "               (math.sqrt(counts_100[2]))]\r\n",
    "\r\n",
    "hamDistList_1000 = []\r\n",
    "hamDistDict_1000 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 1000:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_1000.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_1000.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_1000.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_1000.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_1000.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_1000 = Counter(hamDistList_1000)\r\n",
    "counts_1000 = list(hamDistDict_1000.values())\r\n",
    "tot_err_1000 = sum(counts_1000)\r\n",
    "x_1000 = [0,1,2,3]\r\n",
    "lmbda_1000 = 0.27\r\n",
    "poisson_1000 = poisson.pmf(x_1000, lmbda_1000)\r\n",
    "errors_1000 = [(math.sqrt(counts_1000[0])), (math.sqrt(counts_1000[1])),\r\n",
    "               (math.sqrt(counts_1000[2]))]\r\n",
    "\r\n",
    "# fig, ax = plt.subplots(1, 1)\r\n",
    "# ax.set(xlabel='Bit-flips', ylabel='Counts', ylim=(0,(0.9*tot_err)))\r\n",
    "# ax.bar(hamDistDict_sub1.keys(), hamDistDict_sub1.values(),\r\n",
    "#         label='Experimental data',\r\n",
    "#         color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "#         edgecolor='black',\r\n",
    "#         yerr=errors,\r\n",
    "#         align='center',\r\n",
    "#         ecolor='black',\r\n",
    "#         capsize=2)\r\n",
    "# plt.title(\"Histogram of observed memory errors\")\r\n",
    "# ax2 = ax.twinx()\r\n",
    "# ax2.set(ylabel='Probability of bit-flip', ylim=(0,0.9))\r\n",
    "# plt2 = ax2.plot(x, poisson_pd, 'k-',\r\n",
    "#                 label=f'Poisson distribution, $\\lambda$ = {lmbda}')\r\n",
    "# h1, l1 = ax.get_legend_handles_labels()\r\n",
    "# h2, l2 = ax2.get_legend_handles_labels()\r\n",
    "# ax.legend(h1+h2, l1+l2)\r\n",
    "\r\n",
    "# plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig2 = plt.figure()\r\n",
    "gs0 = gridspec.GridSpec(2, 3, figure=fig2, wspace=0.1)\r\n",
    "rc('xtick', labelsize=8)\r\n",
    "rc('ytick', labelsize=8)\r\n",
    "\r\n",
    "f2_ax1 = fig2.add_subplot(gs0[0, 0])\r\n",
    "f2_ax1.set(ylim=(0,(0.9*tot_err_sub1)))\r\n",
    "f2_ax1.bar(hamDistDict_sub1.keys(), hamDistDict_sub1.values(),\r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_sub1,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax1.margins(0,0)\r\n",
    "f2_ax1.xaxis.set_ticklabels([])\r\n",
    "f2_ax1_2 = f2_ax1.twinx()\r\n",
    "f2_ax1_2.set(ylim=(0,0.9))\r\n",
    "f2_ax1_2.plot(x_sub1, poisson_sub1, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_sub1}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax1_2.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax1_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_sub1}', ha='center', va='center')\r\n",
    "     \r\n",
    "f2_ax2 = fig2.add_subplot(gs0[1, 0])\r\n",
    "f2_ax2.set(ylim=(0,(0.9*tot_err_1)))\r\n",
    "f2_ax2.bar(hamDistDict_1.keys(), hamDistDict_1.values(),\r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_1,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax2.margins(0,0)\r\n",
    "f2_ax2.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
    "f2_ax2_2 = f2_ax2.twinx()\r\n",
    "f2_ax2_2.set(ylim=(0,0.9))\r\n",
    "f2_ax2_2.plot(x_1, poisson_1, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_1}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax2_2.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax2_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_1}', ha='center', va='center')\r\n",
    "\r\n",
    "f2_ax3 = fig2.add_subplot(gs0[0, 1])\r\n",
    "f2_ax3.set(ylim=(0,(0.9*tot_err_10)))\r\n",
    "f2_ax3.bar(hamDistDict_10.keys(), hamDistDict_10.values(), \r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_10,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax3.margins(0,0)\r\n",
    "f2_ax3.xaxis.set_ticklabels([])\r\n",
    "f2_ax3_2 = f2_ax3.twinx()\r\n",
    "f2_ax3_2.set(ylim=(0,0.9))\r\n",
    "f2_ax3_2.plot(x_10, poisson_10, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_10}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax3_2.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax3.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax3_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_10}', ha='center', va='center')\r\n",
    "\r\n",
    "f2_ax4 = fig2.add_subplot(gs0[1, 1])\r\n",
    "f2_ax4.set(ylim=(0,(0.9*tot_err_100)))\r\n",
    "f2_ax4.bar(hamDistDict_100.keys(), hamDistDict_100.values(),\r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_100,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax4.margins(0,0)\r\n",
    "f2_ax4.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
    "f2_ax4_2 = f2_ax4.twinx()\r\n",
    "f2_ax4_2.set(ylim=(0,0.9))\r\n",
    "f2_ax4_2.plot(x_100, poisson_100, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_100}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax4.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax4_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_100}', ha='center', va='center')\r\n",
    "\r\n",
    "f2_ax5 = fig2.add_subplot(gs0[0, 2])\r\n",
    "f2_ax5.set(ylim=(0,(0.9*tot_err_1000)))\r\n",
    "f2_ax5.bar(hamDistDict_1000.keys(), hamDistDict_1000.values(),\r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_1000,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax5.margins(0,0)\r\n",
    "f2_ax5.xaxis.set_ticklabels([])\r\n",
    "f2_ax5_2 = f2_ax5.twinx()\r\n",
    "f2_ax5_2.set(ylim=(0,0.9))\r\n",
    "f2_ax5_2.plot(x_1000, poisson_1000, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_1000}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax5.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax5_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_1000}', ha='center', va='center')\r\n",
    "\r\n",
    "h1, l1 = f2_ax1.get_legend_handles_labels()\r\n",
    "h2, l2 = f2_ax1_2.get_legend_handles_labels()\r\n",
    "l1 = ['Experimental \\ndata']\r\n",
    "l2 = ['Poisson \\ndistribution']\r\n",
    "plt.legend(h1+h2, l1+l2, bbox_to_anchor=(0, -0.8, 1.3, 0.5), prop={'size': 6})\r\n",
    "\r\n",
    "fig2.text(0.5, 0.92, 'Error Frequency', ha='center', fontsize='x-large')\r\n",
    "fig2.text(0.5, 0, 'Bit-flips', ha='center')\r\n",
    "fig2.text(0.01, 0.5, 'Counts', va='center', rotation='vertical')\r\n",
    "fig2.text(1, 0.5, 'Probability of bit-flips occurring', va='center', rotation='vertical')\r\n",
    "\r\n",
    "plt.subplots_adjust(hspace=.0)\r\n",
    "plt.savefig('../../graphs/poisson/fish.svg', format='svg', dpi=1200)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "may20_june16_fluence = 1683696000000\r\n",
    "seconds           = 2332800\r\n",
    "chipir_flux       = may20_june16_fluence / seconds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "sram3_1_half.runs[318].df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run_ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Board</th>\n",
       "      <th>Mikroe_socket</th>\n",
       "      <th>Status</th>\n",
       "      <th>SDC_val</th>\n",
       "      <th>SDC_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-41-495802</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>WRCHCKBRD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-41-511728</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>WRCHCKBRD_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-42-711778</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>WRCHCKBRD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-42-727817</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>WRCHCKBRD_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-43-943728</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>WRCHCKBRD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-43-959721</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>WRCHCKBRD_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-45-175503</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>WRCHCKBRD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-45-191559</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>WRCHCKBRD_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-407500</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>STORE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-423373</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>STORE_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-423586</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>STORE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-439473</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>STORE_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-455557</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>STORE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-471314</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>STORE_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-487452</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>STORE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-487718</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>STORE_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-24-46-503581</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>VERIF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-46-405516</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-47-669477</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>VERIF_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-47-685387</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>VERIF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-47-701307</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>SDC</td>\n",
       "      <td>BA</td>\n",
       "      <td>18454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-48-693297</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>VERIF_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-48-949250</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>VERIF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-48-965119</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-50-213212</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>VERIF_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-50-229155</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>VERIF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-50-229430</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>SDC</td>\n",
       "      <td>A8</td>\n",
       "      <td>6C0B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-50-501246</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>SDC</td>\n",
       "      <td>B2</td>\n",
       "      <td>117FE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-50-949134</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>VERIF_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-477091</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>RECALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-493183</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>RECALL_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-509192</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>RECALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-525128</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>RECALL_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-541091</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>RECALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-557044</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>RECALL_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-573056</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>RECALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-573340</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>RECALL_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-589192</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>VERIF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-51-605074</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-52-789123</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>VERIF_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-52-805039</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>VERIF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-52-820975</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>SDC</td>\n",
       "      <td>8A</td>\n",
       "      <td>1A2A3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-53-892949</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>VERIF_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-54-068903</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>VERIF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-54-071551</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-55-332882</td>\n",
       "      <td>M</td>\n",
       "      <td>C</td>\n",
       "      <td>VERIF_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-55-333218</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>VERIF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-55-348927</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>NE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>318</td>\n",
       "      <td>2021-05-21_15-29-56-596850</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>VERIF_OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run_ID                   Timestamp Board Mikroe_socket        Status  \\\n",
       "0     318  2021-05-21_15-24-41-495802     M             A     WRCHCKBRD   \n",
       "1     318  2021-05-21_15-24-41-511728     M             A  WRCHCKBRD_OK   \n",
       "2     318  2021-05-21_15-24-42-711778     M             B     WRCHCKBRD   \n",
       "3     318  2021-05-21_15-24-42-727817     M             B  WRCHCKBRD_OK   \n",
       "4     318  2021-05-21_15-24-43-943728     M             C     WRCHCKBRD   \n",
       "5     318  2021-05-21_15-24-43-959721     M             C  WRCHCKBRD_OK   \n",
       "6     318  2021-05-21_15-24-45-175503     M             D     WRCHCKBRD   \n",
       "7     318  2021-05-21_15-24-45-191559     M             D  WRCHCKBRD_OK   \n",
       "8     318  2021-05-21_15-24-46-407500     M             A         STORE   \n",
       "9     318  2021-05-21_15-24-46-423373     M             A      STORE_OK   \n",
       "10    318  2021-05-21_15-24-46-423586     M             B         STORE   \n",
       "11    318  2021-05-21_15-24-46-439473     M             B      STORE_OK   \n",
       "12    318  2021-05-21_15-24-46-455557     M             C         STORE   \n",
       "13    318  2021-05-21_15-24-46-471314     M             C      STORE_OK   \n",
       "14    318  2021-05-21_15-24-46-487452     M             D         STORE   \n",
       "15    318  2021-05-21_15-24-46-487718     M             D      STORE_OK   \n",
       "16    318  2021-05-21_15-24-46-503581     M             A         VERIF   \n",
       "17    318  2021-05-21_15-29-46-405516     M             A            NE   \n",
       "18    318  2021-05-21_15-29-47-669477     M             A      VERIF_OK   \n",
       "19    318  2021-05-21_15-29-47-685387     M             B         VERIF   \n",
       "20    318  2021-05-21_15-29-47-701307     M             B           SDC   \n",
       "21    318  2021-05-21_15-29-48-693297     M             B      VERIF_OK   \n",
       "22    318  2021-05-21_15-29-48-949250     M             C         VERIF   \n",
       "23    318  2021-05-21_15-29-48-965119     M             C            NE   \n",
       "24    318  2021-05-21_15-29-50-213212     M             C      VERIF_OK   \n",
       "25    318  2021-05-21_15-29-50-229155     M             D         VERIF   \n",
       "26    318  2021-05-21_15-29-50-229430     M             D           SDC   \n",
       "27    318  2021-05-21_15-29-50-501246     M             D           SDC   \n",
       "28    318  2021-05-21_15-29-50-949134     M             D      VERIF_OK   \n",
       "29    318  2021-05-21_15-29-51-477091     M             A        RECALL   \n",
       "30    318  2021-05-21_15-29-51-493183     M             A     RECALL_OK   \n",
       "31    318  2021-05-21_15-29-51-509192     M             B        RECALL   \n",
       "32    318  2021-05-21_15-29-51-525128     M             B     RECALL_OK   \n",
       "33    318  2021-05-21_15-29-51-541091     M             C        RECALL   \n",
       "34    318  2021-05-21_15-29-51-557044     M             C     RECALL_OK   \n",
       "35    318  2021-05-21_15-29-51-573056     M             D        RECALL   \n",
       "36    318  2021-05-21_15-29-51-573340     M             D     RECALL_OK   \n",
       "37    318  2021-05-21_15-29-51-589192     M             A         VERIF   \n",
       "38    318  2021-05-21_15-29-51-605074     M             A            NE   \n",
       "39    318  2021-05-21_15-29-52-789123     M             A      VERIF_OK   \n",
       "40    318  2021-05-21_15-29-52-805039     M             B         VERIF   \n",
       "41    318  2021-05-21_15-29-52-820975     M             B           SDC   \n",
       "42    318  2021-05-21_15-29-53-892949     M             B      VERIF_OK   \n",
       "43    318  2021-05-21_15-29-54-068903     M             C         VERIF   \n",
       "44    318  2021-05-21_15-29-54-071551     M             C            NE   \n",
       "45    318  2021-05-21_15-29-55-332882     M             C      VERIF_OK   \n",
       "46    318  2021-05-21_15-29-55-333218     M             D         VERIF   \n",
       "47    318  2021-05-21_15-29-55-348927     M             D            NE   \n",
       "48    318  2021-05-21_15-29-56-596850     M             D      VERIF_OK   \n",
       "\n",
       "   SDC_val SDC_loc  \n",
       "0      NaN     NaN  \n",
       "1      NaN     NaN  \n",
       "2      NaN     NaN  \n",
       "3      NaN     NaN  \n",
       "4      NaN     NaN  \n",
       "5      NaN     NaN  \n",
       "6      NaN     NaN  \n",
       "7      NaN     NaN  \n",
       "8      NaN     NaN  \n",
       "9      NaN     NaN  \n",
       "10     NaN     NaN  \n",
       "11     NaN     NaN  \n",
       "12     NaN     NaN  \n",
       "13     NaN     NaN  \n",
       "14     NaN     NaN  \n",
       "15     NaN     NaN  \n",
       "16     NaN     NaN  \n",
       "17     NaN     NaN  \n",
       "18     NaN     NaN  \n",
       "19     NaN     NaN  \n",
       "20      BA   18454  \n",
       "21     NaN     NaN  \n",
       "22     NaN     NaN  \n",
       "23     NaN     NaN  \n",
       "24     NaN     NaN  \n",
       "25     NaN     NaN  \n",
       "26      A8    6C0B  \n",
       "27      B2   117FE  \n",
       "28     NaN     NaN  \n",
       "29     NaN     NaN  \n",
       "30     NaN     NaN  \n",
       "31     NaN     NaN  \n",
       "32     NaN     NaN  \n",
       "33     NaN     NaN  \n",
       "34     NaN     NaN  \n",
       "35     NaN     NaN  \n",
       "36     NaN     NaN  \n",
       "37     NaN     NaN  \n",
       "38     NaN     NaN  \n",
       "39     NaN     NaN  \n",
       "40     NaN     NaN  \n",
       "41      8A   1A2A3  \n",
       "42     NaN     NaN  \n",
       "43     NaN     NaN  \n",
       "44     NaN     NaN  \n",
       "45     NaN     NaN  \n",
       "46     NaN     NaN  \n",
       "47     NaN     NaN  \n",
       "48     NaN     NaN  "
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# TODO: For each run satisfying below conditions, total number of seconds of all runs x flux = fluence for that cross-sec.\r\n",
    "\r\n",
    "counter = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            #counter += run.errors\r\n",
    "            print(run.num, run.errors)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "318 2\n",
      "443 1\n",
      "445 3\n",
      "448 1\n",
      "449 1\n",
      "451 1\n",
      "452 1\n",
      "453 1\n",
      "454 2\n",
      "465 2\n",
      "466 3\n",
      "518 1\n",
      "519 1\n",
      "522 1\n",
      "524 1\n",
      "526 1\n",
      "528 2\n",
      "530 1\n",
      "531 1\n",
      "537 1\n",
      "538 1\n",
      "540 1\n",
      "543 1\n",
      "544 1\n",
      "548 1\n",
      "556 2\n",
      "563 3\n",
      "565 1\n",
      "568 3\n",
      "570 1\n",
      "572 1\n",
      "577 2\n",
      "578 1\n",
      "582 1\n",
      "583 1\n",
      "584 1\n",
      "586 1\n",
      "587 2\n",
      "594 1\n",
      "595 1\n",
      "596 1\n",
      "597 1\n",
      "598 1\n",
      "599 1\n",
      "607 5\n",
      "614 1\n",
      "615 2\n",
      "618 1\n",
      "625 2\n",
      "626 1\n",
      "640 1\n",
      "650 1\n",
      "651 1\n",
      "652 1\n",
      "654 2\n",
      "656 1\n",
      "663 2\n",
      "666 2\n",
      "667 1\n",
      "672 2\n",
      "678 7\n",
      "684 1\n",
      "686 1\n",
      "688 1\n",
      "689 1\n",
      "692 1\n",
      "695 11\n",
      "697 1\n",
      "699 1\n",
      "701 1\n",
      "703 1\n",
      "704 5\n",
      "708 1\n",
      "709 1\n",
      "710 2\n",
      "711 1\n",
      "713 1\n",
      "771 4\n",
      "772 1\n",
      "774 1\n",
      "776 1\n",
      "780 3\n",
      "784 2\n",
      "791 2\n",
      "795 1\n",
      "803 1\n",
      "808 1\n",
      "813 2\n",
      "817 22\n",
      "825 1\n",
      "826 2\n",
      "827 1\n",
      "829 1\n",
      "830 1\n",
      "832 2\n",
      "835 4\n",
      "839 1\n",
      "842 1\n",
      "849 1\n",
      "857 2\n",
      "858 1\n",
      "859 1\n",
      "861 1\n",
      "863 2\n",
      "864 2\n",
      "865 1\n",
      "866 2\n",
      "870 2\n",
      "885 1\n",
      "890 2\n",
      "891 2\n",
      "892 2\n",
      "896 1\n",
      "899 2\n",
      "901 2\n",
      "902 3\n",
      "906 1\n",
      "913 4\n",
      "922 1\n",
      "925 1\n",
      "931 2\n",
      "937 1\n",
      "941 1\n",
      "944 1\n",
      "947 3\n",
      "953 3\n",
      "963 2\n",
      "966 1\n",
      "969 1\n",
      "971 1\n",
      "973 1\n",
      "975 1\n",
      "976 2\n",
      "980 1\n",
      "981 1\n",
      "982 1\n",
      "988 1\n",
      "996 2\n",
      "998 1\n",
      "1001 2\n",
      "1004 3\n",
      "1006 1\n",
      "1012 3\n",
      "1015 1\n",
      "1016 1\n",
      "1018 1\n",
      "1021 1\n",
      "1023 1\n",
      "1024 3\n",
      "1025 1\n",
      "1034 2\n",
      "1035 2\n",
      "1036 1\n",
      "1038 1\n",
      "1039 1\n",
      "1040 1\n",
      "1042 2\n",
      "1044 1\n",
      "1045 1\n",
      "1046 1\n",
      "1050 1\n",
      "1055 2\n",
      "1066 2\n",
      "1070 1\n",
      "1072 2\n",
      "1075 2\n",
      "1076 1\n",
      "1079 1\n",
      "1084 2\n",
      "1085 1\n",
      "1086 2\n",
      "1087 1\n",
      "1097 5\n",
      "1100 2\n",
      "1102 2\n",
      "1103 1\n",
      "1105 1\n",
      "1106 2\n",
      "1121 2\n",
      "1123 2\n",
      "1126 2\n",
      "1129 2\n",
      "1130 3\n",
      "1131 1\n",
      "1135 2\n",
      "1140 1\n",
      "1156 2\n",
      "1157 2\n",
      "1164 3\n",
      "1166 1\n",
      "1167 1\n",
      "1174 2\n",
      "1178 2\n",
      "1184 1\n",
      "1192 1\n",
      "1195 2\n",
      "1201 1\n",
      "1203 1\n",
      "1207 1\n",
      "1215 1\n",
      "1216 1\n",
      "1217 1\n",
      "1218 1\n",
      "1219 1\n",
      "1220 1\n",
      "1221 1\n",
      "1222 1\n",
      "1230 1\n",
      "1231 1\n",
      "1232 3\n",
      "1235 1\n",
      "1236 1\n",
      "1238 1\n",
      "1240 1\n",
      "1244 1\n",
      "1249 2\n",
      "1251 1\n",
      "1254 2\n",
      "1269 1\n",
      "1272 1\n",
      "1274 2\n",
      "1275 1\n",
      "1285 1\n",
      "1337 1\n",
      "1338 1\n",
      "1343 2\n",
      "1346 1\n",
      "1356 1\n",
      "1358 1\n",
      "1359 1\n",
      "1361 1\n",
      "1365 1\n",
      "1368 1\n",
      "1370 1\n",
      "1372 1\n",
      "1376 1\n",
      "1379 2\n",
      "1382 3\n",
      "1385 1\n",
      "1388 1\n",
      "1390 2\n",
      "1391 1\n",
      "1392 3\n",
      "1393 1\n",
      "1394 3\n",
      "1395 3\n",
      "1396 1\n",
      "1397 1\n",
      "1398 1\n",
      "1401 1\n",
      "1404 1\n",
      "1405 1\n",
      "1406 1\n",
      "1407 1\n",
      "1408 2\n",
      "1410 1\n",
      "1412 2\n",
      "1417 1\n",
      "1424 1\n",
      "1426 2\n",
      "1428 1\n",
      "1431 2\n",
      "1434 1\n",
      "1440 2\n",
      "1442 1\n",
      "1443 2\n",
      "1446 1\n",
      "1448 2\n",
      "1450 1\n",
      "1451 2\n",
      "1453 1\n",
      "1455 1\n",
      "1461 5\n",
      "1465 1\n",
      "1466 1\n",
      "1468 1\n",
      "1469 2\n",
      "1471 2\n",
      "1473 1\n",
      "1475 2\n",
      "1476 1\n",
      "1480 2\n",
      "1481 1\n",
      "1482 1\n",
      "1484 1\n",
      "1497 1\n",
      "1504 2\n",
      "1506 1\n",
      "1515 1\n",
      "1516 1\n",
      "1518 1\n",
      "1519 3\n",
      "1520 1\n",
      "1523 1\n",
      "1526 2\n",
      "1527 2\n",
      "1531 1\n",
      "1533 1\n",
      "1535 1\n",
      "1538 2\n",
      "1539 2\n",
      "1550 1\n",
      "1557 1\n",
      "1561 1\n",
      "1566 1\n",
      "1567 1\n",
      "1568 1\n",
      "1569 1\n",
      "1574 2\n",
      "1579 2\n",
      "1580 1\n",
      "1581 2\n",
      "1583 1\n",
      "1584 1\n",
      "1587 2\n",
      "1592 1\n",
      "1595 1\n",
      "1597 1\n",
      "1602 1\n",
      "1616 1\n",
      "1617 1\n",
      "1620 1\n",
      "1625 1\n",
      "1626 1\n",
      "1627 1\n",
      "1631 1\n",
      "1632 2\n",
      "1642 1\n",
      "1643 1\n",
      "1647 1\n",
      "1648 1\n",
      "1649 3\n",
      "1651 2\n",
      "1655 1\n",
      "1656 1\n",
      "1657 1\n",
      "1661 1\n",
      "1662 1\n",
      "1905 2\n",
      "1907 3\n",
      "1909 3\n",
      "1913 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "counter / may20_june16_fluence"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.939314460567703e-13"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "68e83ffa79d15a4f3f363f7e2d730fba250349155b7434a2a310aead7dfd6146"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}