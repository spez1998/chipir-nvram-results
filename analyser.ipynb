{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from collections import Counter\r\n",
    "from datetime import datetime, timedelta as td\r\n",
    "import math\r\n",
    "from matplotlib import gridspec, pyplot as plt, rc, ticker\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "from scipy.stats import poisson\r\n",
    "import sys\r\n",
    "\r\n",
    "dtf = datetime.strftime\r\n",
    "dtp = datetime.strptime\r\n",
    "\r\n",
    "plt.style.use(['science','ieee'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class ExpLogHandler:\r\n",
    "    \"\"\"Class to find, combine, and pre-process all required data files.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        log_names (list): List of names of required log files.\r\n",
    "\r\n",
    "    Attributes:\r\n",
    "        log_names (list): Where log_names is stored.\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, log_names):\r\n",
    "        \"\"\"Initialiser for the ExpLogHandler class.\r\n",
    "\r\n",
    "        Args:\r\n",
    "            log_names (list): List of names of required log files.\r\n",
    "        \"\"\"\r\n",
    "        self.log_names = log_names\r\n",
    "        \r\n",
    "    def getData(self):\r\n",
    "        \"\"\"Acquire data files, combine, remove duplicate column headers, join indices\r\n",
    "\r\n",
    "        Args:\r\n",
    "            None\r\n",
    "        \r\n",
    "        Returns:\r\n",
    "            data: Complete DataFrame of all experiment log lines.\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        self.data = pd.read_csv(self.log_names[0], on_bad_lines=\"skip\", dtype={'SDC_val': str})\r\n",
    "        for i in range(1, len(self.log_names)):\r\n",
    "            data_next   = pd.read_csv(self.log_names[i], on_bad_lines=\"skip\", dtype={'SDC_val': str})\r\n",
    "            data_frames = [self.data, data_next]\r\n",
    "            self.data   = pd.concat(data_frames, ignore_index=True)\r\n",
    "        self.data.drop(self.data.loc[(self.data[\"Timestamp\"] == \"Timestamp\")].index.tolist())\r\n",
    "        self.dataLength = self.data.shape[0]\r\n",
    "\r\n",
    "        wrchckbrdLocs  = self.data.loc[(self.data[\"Board\"] == \"M\") & (self.data[\"Mikroe_socket\"] == \"A\") &\r\n",
    "                                       (self.data[\"Status\"] == \"WRCHCKBRD\")].index.tolist()\r\n",
    "        wrchckbrdIndex = [(i, \"WRCHCKBRD\") for i in wrchckbrdLocs]\r\n",
    "        initLocs       = self.data.loc[(self.data[\"Board\"] == \"M\") & (self.data[\"Mikroe_socket\"] == \"A\") &\r\n",
    "                         (self.data[\"Status\"] == \"INIT\")].index.tolist()\r\n",
    "        initIndex      = [(i, \"INIT\") for i in initLocs]\r\n",
    "        runIndex       = wrchckbrdIndex + initIndex\r\n",
    "        runIndex       = sorted(runIndex)\r\n",
    "        runIndex.append((self.dataLength, \"END\"))\r\n",
    "\r\n",
    "        runId  = 1\r\n",
    "        runCol = [''] * self.dataLength\r\n",
    "        for h in range(len(runIndex) - 1):\r\n",
    "            if runIndex[h][1] == \"WRCHCKBRD\":\r\n",
    "                start              = runIndex[h][0]\r\n",
    "                end                = runIndex[h+1][0]\r\n",
    "                runCol[start:end]  = [runId]*(end-start)\r\n",
    "                runId              += 1\r\n",
    "\r\n",
    "        self.data.insert(loc=0, column=\"Run_ID\", value=runCol)\r\n",
    "        return self.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class BeamLogHandler:\r\n",
    "    \"\"\"Class to retrieve all neutron logs for experiment dates.\r\n",
    "\r\n",
    "    Attributes:\r\n",
    "        beamLogFnameFormat (str): Datetime format for beamlog file names.\r\n",
    "        firstTime (datetime): Datetime object of first experiment timestamp.\r\n",
    "        lastTime (datetime): Datetime object of last experiment timestamp.\r\n",
    "        targetDir_fullpathList (list): List of each parent directory of experiment results directory.\r\n",
    "    \r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, firstTime, lastTime, targetDir_fullpathList):     \r\n",
    "        self.beamLogFnameFormat          = \"%Y-%m-%d\"\r\n",
    "        self.firstTime                   = firstTime\r\n",
    "        self.lastTime                    = lastTime\r\n",
    "        self.targetDir_fullpathList      = targetDir_fullpathList\r\n",
    "        self.targetDir_fullpathList[-4:] = [\"neutrons\"]\r\n",
    "\r\n",
    "    def getLogs(self):\r\n",
    "        firstBeamTime = dtf(self.firstTime, self.beamLogFnameFormat)\r\n",
    "        beamlogDayDif = (self.lastTime - self.firstTime).days\r\n",
    "        beamPath      = \"../../../neutrons/countlog-\"\r\n",
    "        self.beamlog  = pd.read_csv(f\"{beamPath}{firstBeamTime}.txt\",\r\n",
    "                        delim_whitespace=True, header=None, skiprows=1)\r\n",
    "        nextTime      = self.firstTime\r\n",
    "        for i in range(0, beamlogDayDif+1):\r\n",
    "            nextTime      = nextTime + td(days=1)\r\n",
    "            nextBeamTime  = dtf(nextTime, self.beamLogFnameFormat)\r\n",
    "            try:\r\n",
    "                nextBeamlog   = pd.read_csv(f\"{beamPath}{nextBeamTime}.txt\",delim_whitespace=True,header=None,skiprows=1)\r\n",
    "            except FileNotFoundError:\r\n",
    "                pass\r\n",
    "            beamlogFrames = [self.beamlog, nextBeamlog]\r\n",
    "            self.beamlog  = pd.concat(beamlogFrames, ignore_index=True)\r\n",
    "            \r\n",
    "        self.beamlog.columns = [\"Date\",\"HMS_time\",\"Millisecs\",\"Count1\",\"Count2\",\r\n",
    "                                \"Count3\",\"Count4\",\"protonCharge\",\"Beam_current\"]\r\n",
    "        return self.beamlog"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Run:\r\n",
    "    \"\"\"Class for one repetition of an experiment.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        num (int): Run number for the selected experiment logs.\r\n",
    "        runData (DataFrame): Truncated DataFrame of log lines for the run.\r\n",
    "    \r\n",
    "    Attributes:\r\n",
    "        delay (int): Length in milliseconds of beam 'bathing time'.\r\n",
    "        df (DataFrame): Saving runData.\r\n",
    "        errors (int): Number of nvRAM errors.\r\n",
    "        fullErr (int): 1 if the entire nvRAM array was errored.\r\n",
    "        hot (int): 1 if the beam was on, 0 if not.\r\n",
    "        num (int): Saving num.\r\n",
    "        rowErr (int): 1 if there was at least one row error.\r\n",
    "        see (int): Number of true SEEs detected.\r\n",
    "        valid (int): 1 if the run had all expected log lines, 0 if not.\r\n",
    "        _ErrorsNVRAM (list): List of tuples (error_byte, error_location) for each chip.\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, num, runData):\r\n",
    "        \"\"\"Initialiser for the Run class. \r\n",
    "\r\n",
    "        Parameters:\r\n",
    "            num (int): Run number for the selected experiment logs.\r\n",
    "            runData (DataFrame): Truncated DataFrame of log lines for the run.\r\n",
    "        \"\"\"\r\n",
    "        self.delay     = -1\r\n",
    "        self.df        = runData\r\n",
    "        self.errors    = 0\r\n",
    "        self.fullErr   = -1\r\n",
    "        self.hot       = -1\r\n",
    "        self.num       = num\r\n",
    "        self.rowErr    = -1\r\n",
    "        self.see       = -1\r\n",
    "        self.valid     = -1\r\n",
    "        self.aErrNVRAM = []\r\n",
    "        self.bErrNVRAM = []\r\n",
    "        self.cErrNVRAM = []\r\n",
    "        self.dErrNVRAM = []\r\n",
    "        self.aErrorBounds = []\r\n",
    "        self.bErrorBounds = []\r\n",
    "        self.cErrorBounds = []\r\n",
    "        self.dErrorBounds = []\r\n",
    "        self.aErrNVRAMVals = []\r\n",
    "        self.bErrNVRAMVals = []\r\n",
    "        self.cErrNVRAMVals = []\r\n",
    "        self.dErrNVRAMVals = []\r\n",
    "        self.aErrNVRAMLocs = []\r\n",
    "        self.bErrNVRAMLocs = []\r\n",
    "        self.cErrNVRAMLocs = []\r\n",
    "        self.dErrNVRAMLocs = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Analyser:\r\n",
    "    '''\r\n",
    "    Class to handle processing data.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        targetDir_fullpath (string): File path of directory to analyse.\r\n",
    "\r\n",
    "    Attributes:\r\n",
    "        targetDir_fullpath (string): Storing targetDir_fullpath arg.\r\n",
    "        expLogTstampFormat (string): Datetime format for experiment log timestamps\r\n",
    "        beamLogTstampFormat (string): Datetime format for beam log timestamps                \r\n",
    "    '''\r\n",
    "    def __init__(self, targDir_full):\r\n",
    "        '''\r\n",
    "        Retrieve + store target directory, initialise datetime formats.\r\n",
    "\r\n",
    "        Args:\r\n",
    "            targetDir_fullpath (string): File path of directory to analyse.\r\n",
    "\r\n",
    "        Attributes:\r\n",
    "            ignores (string): Experiment run IDs to ignore during processing\r\n",
    "            targetDir_fullpath (string): Storing targetDir_fullpath arg.\r\n",
    "            expLogTstampFormat (string): Datetime format for experiment log timestamps\r\n",
    "            beamLogTstampFormat (string): Datetime format for beam log timestamps\r\n",
    "        '''\r\n",
    "        self.ignores = []\r\n",
    "        self.targDir_full = targDir_full\r\n",
    "        self.expLogTstampFormat  = \"%Y-%m-%d_%H-%M-%S-%f\"\r\n",
    "        self.beamLogTstampFormat = \"%d/%m/%Y %H:%M:%S\"\r\n",
    " \r\n",
    "    def setup(self):\r\n",
    "        #targetDir_fullpathList = self.targDir_full.split(\"/\")\r\n",
    "        targDir_fullList = self.targDir_full.split(\"/\")\r\n",
    "        targDir_trunc    = targDir_fullList[-4:-1]\r\n",
    "        self.chip        = targDir_trunc[0]\r\n",
    "        self.variant     = targDir_trunc[1]\r\n",
    "        self.size        = targDir_trunc[2]\r\n",
    "\r\n",
    "        # Get data from logs\r\n",
    "        self.log_names     = [self.targDir_full+i for i in os.listdir(self.targDir_full) if \".csv\" in i]\r\n",
    "        self.log_names.sort(key = lambda x: dtp(x, f\"{self.targDir_full}nvRAM_data_%d-%m-%Y-%H%M.csv\"))\r\n",
    "        self.ExpLogHandler = ExpLogHandler(self.log_names)\r\n",
    "        self.data          = self.ExpLogHandler.getData()\r\n",
    "\r\n",
    "        # Get beam status from logs\r\n",
    "        firstTimestamp      = self.data[0:1]['Timestamp'][0]\r\n",
    "        lastTimestamp       = self.data[self.data.shape[0]-2:self.data.shape[0]-1]['Timestamp'][self.data.shape[0]-2]\r\n",
    "        firstTime           = dtp(firstTimestamp, self.expLogTstampFormat)\r\n",
    "        lastTime            = dtp(lastTimestamp, self.expLogTstampFormat)\r\n",
    "        self.BeamLogHandler = BeamLogHandler(firstTime, lastTime, targDir_fullList)\r\n",
    "        self.beamlog        = self.BeamLogHandler.getLogs()\r\n",
    "\r\n",
    "        # Create datetime objects from beamlog timestamps\r\n",
    "        beamlogTstamps    = (self.beamlog['Date']+self.beamlog['HMS_time']+self.beamlog['Millisecs'].apply(str)).tolist()\r\n",
    "        self.beamlogTimes = []\r\n",
    "        for i in beamlogTstamps:\r\n",
    "            if len(i) > 23:\r\n",
    "                i = i[0:26]\r\n",
    "            self.beamlogTimes.append(i)\r\n",
    "        self.beamlogTimes = [dtp(i, '%d/%m/%Y%H:%M:%S0.%f') for i in self.beamlogTimes]\r\n",
    "\r\n",
    "    def beamOn(self, firstTstamp, lastTstamp):\r\n",
    "        bOfirstTime = firstTstamp\r\n",
    "        bOlastTime = lastTstamp\r\n",
    "        beamTimeNearFirstTime = min([i for i in self.beamlogTimes if i <= bOfirstTime], key=lambda x: abs(x - bOfirstTime))\r\n",
    "        beamTimeNearLastTime  = min([i for i in self.beamlogTimes if i >= bOlastTime], key=lambda x: abs(x - bOlastTime))\r\n",
    "        firstRow              = self.beamlog.loc[(self.beamlog['Date'] == dtf(beamTimeNearFirstTime, '%d/%m/%Y')) &\r\n",
    "                                (self.beamlog['HMS_time'] == dtf(beamTimeNearFirstTime, '%H:%M:%S'))]\r\n",
    "        lastRow               = self.beamlog.loc[(self.beamlog['Date'] == dtf(beamTimeNearLastTime, '%d/%m/%Y')) & \r\n",
    "                                (self.beamlog['HMS_time'] == dtf(beamTimeNearLastTime, '%H:%M:%S'))]\r\n",
    "        count4Dif             = lastRow.iloc[0]['Count4'] - firstRow.iloc[0]['Count4']\r\n",
    "        numRows               = lastRow.index.astype(int)[0] - firstRow.index.astype(int)[0]\r\n",
    "        cps                   = count4Dif / numRows\r\n",
    "        if cps > 1:\r\n",
    "            return 1\r\n",
    "        return 0\r\n",
    "\r\n",
    "    def createRuns(self):\r\n",
    "        runNames  = []\r\n",
    "        self.runs = {}\r\n",
    "        lastRunID =  self.data[self.data['Run_ID'].last_valid_index():self.data['Run_ID'].\r\n",
    "                     last_valid_index()+1]['Run_ID'][self.data['Run_ID'].last_valid_index()]\r\n",
    "\r\n",
    "        # Supply Run initialiser with truncated data \r\n",
    "        for i in range(1, lastRunID + 1):\r\n",
    "            runNames.append(f\"run_{i}\")\r\n",
    "            runData      = self.data.loc[(self.data[\"Run_ID\"] == i)]\r\n",
    "            runData.reset_index(inplace=True, drop=True)\r\n",
    "            self.runs[i] = Run(i, runData)\r\n",
    "\r\n",
    "        for run in self.runs.values():\r\n",
    "            if self.variant == \"1\":\r\n",
    "                    try:\r\n",
    "                        # Extract beam delay from timestamps\r\n",
    "                        before_delay_i  = run.df.loc[(run.df['Mikroe_socket']=='D') & (run.df['Status']=='STORE_OK')].index[0]\r\n",
    "                        before_delay_t  = run.df.loc[before_delay_i]['Timestamp']\r\n",
    "                        after_delay_i   = run.df.loc[(run.df['Mikroe_socket']=='A') & (run.df['Status']=='VERIF')].index[0] + 1\r\n",
    "                        after_delay_t   = run.df.loc[after_delay_i]['Timestamp']\r\n",
    "                        before_delay_dt = dtp(before_delay_t, self.expLogTstampFormat)\r\n",
    "                        after_delay_dt  = dtp(after_delay_t, self.expLogTstampFormat)   \r\n",
    "                        dif             = after_delay_dt - before_delay_dt\r\n",
    "                        \r\n",
    "                        if dif < td(seconds = 0.5):\r\n",
    "                            run.delay = 0.1\r\n",
    "                        if td(seconds = 0.5) < dif < td(seconds = 5):\r\n",
    "                            run.delay = 1\r\n",
    "                        if td(seconds = 5)   < dif < td(seconds = 50):\r\n",
    "                            run.delay = 10\r\n",
    "                        if td(seconds = 50)  < dif < td(seconds = 500):\r\n",
    "                            run.delay = 100\r\n",
    "                        if td(seconds = 500) < dif < td(seconds = 5000):\r\n",
    "                            run.delay = 1000\r\n",
    "\r\n",
    "                        # Was the beam on?\r\n",
    "                        try:\r\n",
    "                            if self.beamOn(before_delay_dt, after_delay_dt):\r\n",
    "                                run.hot = 1\r\n",
    "                            else:\r\n",
    "                                run.hot = 0\r\n",
    "                        except ValueError:\r\n",
    "                            print(run.name)\r\n",
    "\r\n",
    "                        # Create list of errors in nvRAM per chip\r\n",
    "                        aErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                                run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                        bErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                                run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") &\r\n",
    "                                            (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                        cErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                                run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                        dErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                                run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                            (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                        aErrorsBefRec = list(zip(run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                        aErrorsAftRec = list(zip(run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                        bErrorsBefRec = list(zip(run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                        bErrorsAftRec = list(zip(run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                        cErrorsBefRec = list(zip(run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                        cErrorsAftRec = list(zip(run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                        dErrorsBefRec = list(zip(run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                        dErrorsAftRec = list(zip(run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                                run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_loc\"].values.tolist())) \r\n",
    "                        \r\n",
    "                        run.aErrNVRAM = [i for i in bErrorsAftRec if i not in bErrorsBefRec if np.nan not in i]\r\n",
    "                        run.bErrNVRAM = [i for i in bErrorsAftRec if i not in bErrorsBefRec if np.nan not in i]\r\n",
    "                        run.cErrNVRAM = [i for i in cErrorsAftRec if i not in cErrorsBefRec if np.nan not in i]\r\n",
    "                        run.dErrNVRAM = [i for i in dErrorsAftRec if i not in dErrorsBefRec if np.nan not in i]\r\n",
    "\r\n",
    "                        run.errors += len(run.aErrNVRAM)\r\n",
    "                        run.errors += len(run.bErrNVRAM)\r\n",
    "                        run.errors += len(run.cErrNVRAM)\r\n",
    "                        run.errors += len(run.dErrNVRAM)\r\n",
    "\r\n",
    "                    except IndexError:\r\n",
    "                        run.valid = 0\r\n",
    "                    else:\r\n",
    "                        run.valid = 1\r\n",
    "                        \r\n",
    "            if self.variant == \"2\":\r\n",
    "                try:\r\n",
    "                    # Extract beam delay from timestamps\r\n",
    "                    before_delay_i  = run.df.loc[(run.df['Mikroe_socket']=='D') & (run.df['Status']=='STORE_OK')].index[0]\r\n",
    "                    before_delay_t  = run.df.loc[before_delay_i]['Timestamp']\r\n",
    "                    after_delay_i   = run.df.loc[(run.df['Mikroe_socket']=='A') & (run.df['Status']=='VERIF')].index[0] + 1\r\n",
    "                    after_delay_t   = run.df.loc[after_delay_i]['Timestamp']\r\n",
    "                    before_delay_dt = dtp(before_delay_t, self.expLogTstampFormat)\r\n",
    "                    after_delay_dt  = dtp(after_delay_t, self.expLogTstampFormat)   \r\n",
    "                    dif             = after_delay_dt - before_delay_dt\r\n",
    "                    \r\n",
    "                    if td(seconds = 0.1) < dif < td(seconds = 0.5):\r\n",
    "                        run.delay = 0.1\r\n",
    "                    if td(seconds = 0.5) < dif < td(seconds = 5):\r\n",
    "                        run.delay = 1\r\n",
    "                    if td(seconds = 5)   < dif < td(seconds = 50):\r\n",
    "                        run.delay = 10\r\n",
    "                    if td(seconds = 50)  < dif < td(seconds = 500):\r\n",
    "                        run.delay = 100\r\n",
    "                    if td(seconds = 500) < dif < td(seconds = 5000):\r\n",
    "                        run.delay = 1000\r\n",
    "\r\n",
    "                    # Was the beam on?\r\n",
    "                    try:\r\n",
    "                        if self.beamOn(before_delay_dt, after_delay_dt):\r\n",
    "                            run.hot = 1\r\n",
    "                        else:\r\n",
    "                            run.hot = 0\r\n",
    "                    except ValueError:\r\n",
    "                        print(run.name)\r\n",
    "                        \r\n",
    "                    # Create list of errors in nvRAM per chip\r\n",
    "                    aErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                            run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                    bErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                            run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") &\r\n",
    "                                        (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                    cErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                            run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                    dErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                            run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                        (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                    aErrBefDelay = list(zip(run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    aErrBefRec = list(zip(run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    aErrAftRec = list(zip(run.df[aErrorBounds[2][0]+1:aErrorBounds[2][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[aErrorBounds[2][0]+1:aErrorBounds[2][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                    bErrBefDelay = list(zip(run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    bErrBefRec = list(zip(run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    bErrAftRec = list(zip(run.df[bErrorBounds[2][0]+1:bErrorBounds[2][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[bErrorBounds[2][0]+1:bErrorBounds[2][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    \r\n",
    "                    cErrBefDelay = list(zip(run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    cErrBefRec = list(zip(run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    cErrAftRec = list(zip(run.df[cErrorBounds[2][0]+1:cErrorBounds[2][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[cErrorBounds[2][0]+1:cErrorBounds[2][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    \r\n",
    "                    dErrBefDelay = list(zip(run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    dErrBefRec = list(zip(run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    dErrAftRec = list(zip(run.df[dErrorBounds[2][0]+1:dErrorBounds[2][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                            run.df[dErrorBounds[2][0]+1:dErrorBounds[2][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                    \r\n",
    "                    run.aErrNVRAM = [i for i in aErrAftRec if i not in aErrBefDelay if i not in aErrBefRec if np.nan not in i]\r\n",
    "                    run.bErrNVRAM = [i for i in bErrAftRec if i not in bErrBefDelay if i not in bErrBefRec if np.nan not in i]\r\n",
    "                    run.cErrNVRAM = [i for i in cErrAftRec if i not in cErrBefDelay if i not in cErrBefRec if np.nan not in i]\r\n",
    "                    run.dErrNVRAM = [i for i in dErrAftRec if i not in dErrBefDelay if i not in dErrBefRec if np.nan not in i]\r\n",
    "                    \r\n",
    "                    run.errors += len(run.aErrNVRAM)\r\n",
    "                    run.errors += len(run.bErrNVRAM)\r\n",
    "                    run.errors += len(run.cErrNVRAM)\r\n",
    "                    run.errors += len(run.dErrNVRAM)\r\n",
    "\r\n",
    "                # Invalidate run if critical experiment steps didn't occur\r\n",
    "                except IndexError:\r\n",
    "                    run.valid = 0\r\n",
    "                else:\r\n",
    "                    run.valid = 1\r\n",
    "\r\n",
    "\r\n",
    "    def diffFinder(self, variant):\r\n",
    "        '''Find runs with large patterns in error location.\r\n",
    "        '''\r\n",
    "        patterns = []\r\n",
    "        for run in variant.values():    \r\n",
    "            diffA = [int(run.aErrNVRAM[i+1][1], 16) - int(run.aErrNVRAM[i][1], 16) \r\n",
    "                            for i in range(0, len(run.aErrNVRAM)-1)]\r\n",
    "            diffB = [int(run.bErrNVRAM[i+1][1], 16) - int(run.bErrNVRAM[i][1], 16)\r\n",
    "                            for i in range(0, len(run.bErrNVRAM)-1)]\r\n",
    "            diffC = [int(run.cErrNVRAM[i+1][1], 16) - int(run.cErrNVRAM[i][1], 16)\r\n",
    "                            for i in range(0, len(run.cErrNVRAM)-1)]\r\n",
    "            diffD = [int(run.dErrNVRAM[i+1][1], 16) - int(run.dErrNVRAM[i][1], 16)\r\n",
    "                            for i in range(0, len(run.dErrNVRAM)-1)]\r\n",
    "\r\n",
    "            diffA2 = [abs(diffA[i+1] - diffA[i]) for i in range(0, len(diffA)-1)]\r\n",
    "            diffB2 = [abs(diffB[i+1] - diffB[i]) for i in range(0, len(diffB)-1)]\r\n",
    "            diffC2 = [abs(diffC[i+1] - diffC[i]) for i in range(0, len(diffC)-1)]\r\n",
    "            diffD2 = [abs(diffD[i+1] - diffD[i]) for i in range(0, len(diffD)-1)]\r\n",
    "\r\n",
    "            diffADict1 = {k: v for k, v in sorted(Counter(diffA).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffBDict1 = {k: v for k, v in sorted(Counter(diffB).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffCDict1 = {k: v for k, v in sorted(Counter(diffC).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffDDict1 = {k: v for k, v in sorted(Counter(diffD).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "\r\n",
    "            diffADict2 = {k: v for k, v in sorted(Counter(diffA2).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffBDict2 = {k: v for k, v in sorted(Counter(diffB2).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffCDict2 = {k: v for k, v in sorted(Counter(diffC2).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            diffDDict2 = {k: v for k, v in sorted(Counter(diffD2).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "\r\n",
    "            lastMemDigitA = [i[1][-1] for i in run.aErrNVRAM]\r\n",
    "            lastMemDigitB = [i[1][-1] for i in run.bErrNVRAM]\r\n",
    "            lastMemDigitC = [i[1][-1] for i in run.cErrNVRAM]\r\n",
    "            lastMemDigitD = [i[1][-1] for i in run.dErrNVRAM]\r\n",
    "\r\n",
    "            lmdADict = {k: v for k, v in sorted(Counter(lastMemDigitA).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            lmdBDict = {k: v for k, v in sorted(Counter(lastMemDigitB).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            lmdCDict = {k: v for k, v in sorted(Counter(lastMemDigitC).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "            lmdDDict = {k: v for k, v in sorted(Counter(lastMemDigitD).items(), reverse=True, key=lambda i: i[1])}\r\n",
    "\r\n",
    "            if diffADict2:\r\n",
    "                tot_err = len(run.aErrNVRAM)\r\n",
    "                if list(diffADict2.items())[:1][0][1] >= 5:\r\n",
    "                    if (list(diffADict2.items())[:1][0][1] / tot_err) > 0.1:\r\n",
    "                        patterns.append(run.num)\r\n",
    "\r\n",
    "            if diffBDict2:\r\n",
    "                tot_err = len(run.bErrNVRAM)\r\n",
    "                if list(diffBDict2.items())[:1][0][1] >= 5:\r\n",
    "                    if (list(diffBDict2.items())[:1][0][1] / tot_err) > 0.1:\r\n",
    "                        patterns.append(run.num)\r\n",
    "            \r\n",
    "            if diffCDict2:\r\n",
    "                tot_err = len(run.cErrNVRAM)\r\n",
    "                if list(diffCDict2.items())[:1][0][1] >= 5:\r\n",
    "                    if (list(diffCDict2.items())[:1][0][1] / tot_err) > 0.1:\r\n",
    "                        patterns.append(run.num)\r\n",
    "\r\n",
    "            if diffDDict2:\r\n",
    "                tot_err = len(run.dErrNVRAM)\r\n",
    "                if list(diffDDict2.items())[:1][0][1] >= 5:\r\n",
    "                    if (list(diffDDict2.items())[:1][0][1] / tot_err) > 0.1:\r\n",
    "                        patterns.append(run.num)\r\n",
    "                        \r\n",
    "            else:\r\n",
    "                if lmdADict:\r\n",
    "                    if list(lmdADict.items())[:1][0][1] >= 5:\r\n",
    "                        tot_err = len(run.aErrNVRAM)\r\n",
    "                        if (list(lmdADict.items())[:1][0][1] / tot_err) > 0.75:\r\n",
    "                            patterns.append(run.num)\r\n",
    "\r\n",
    "                if lmdBDict:\r\n",
    "                    if list(lmdBDict.items())[:1][0][1] >= 5:\r\n",
    "                        tot_err = len(run.bErrNVRAM)\r\n",
    "                        if (list(lmdBDict.items())[:1][0][1] / tot_err) > 0.75:\r\n",
    "                            patterns.append(run.num)\r\n",
    "\r\n",
    "                if lmdCDict:\r\n",
    "                    if list(lmdCDict.items())[:1][0][1] >= 5:\r\n",
    "                        tot_err = len(run.cErrNVRAM)\r\n",
    "                        if (list(lmdCDict.items())[:1][0][1] / tot_err) > 0.75:\r\n",
    "                            patterns.append(run.num)\r\n",
    "\r\n",
    "                if lmdDDict:\r\n",
    "                    if list(lmdDDict.items())[:1][0][1] >= 5:\r\n",
    "                        tot_err = len(run.dErrNVRAM)\r\n",
    "                        if (list(lmdDDict.items())[:1][0][1] / tot_err) > 0.75:\r\n",
    "                            patterns.append(run.num)\r\n",
    "                else:\r\n",
    "                    continue\r\n",
    "\r\n",
    "        return sorted(list(set(patterns)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "sram3_1_single   = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/SRAM3/1/single/\")\r\n",
    "sram3_1_single.setup()\r\n",
    "sram3_1_single.createRuns()\r\n",
    "sram3_1_single.ignores = sram3_1_single.diffFinder(sram3_1_single.runs)\r\n",
    "print(\"sram3_1_single ready\")\r\n",
    "\r\n",
    "sram3_1_half     = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/SRAM3/1/half/\")\r\n",
    "sram3_1_half.setup()\r\n",
    "sram3_1_half.createRuns()\r\n",
    "sram3_1_half.ignores = sram3_1_half.diffFinder(sram3_1_half.runs)\r\n",
    "more_ignores = [8,10,12,14,17,21,22,23,24,25,26,362,363,370,371,372,375,376,377,378,381,382,385,386,387,388,389,392,397,398,\r\n",
    "                400,401,404,406,407,408,414,415,416,417,418,430,431,432,433,434,1542,1613]\r\n",
    "sram3_1_half.ignores.extend(more_ignores)\r\n",
    "print(\"sram3_1_half ready\")\r\n",
    "\r\n",
    "sram3_2_half     = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/SRAM3/2/half/\")\r\n",
    "sram3_2_half.setup()\r\n",
    "sram3_2_half.createRuns()\r\n",
    "sram3_2_half.ignores = sram3_2_half.diffFinder(sram3_2_half.runs)\r\n",
    "print(\"sram3_2_half ready\")\r\n",
    "\r\n",
    "nvsram2_1_single = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/nvSRAM2/1/single/\")\r\n",
    "nvsram2_1_single.setup()\r\n",
    "nvsram2_1_single.createRuns()\r\n",
    "nvsram2_1_single.ignores = nvsram2_1_single.diffFinder(nvsram2_1_single.runs)\r\n",
    "print(\"nvsram2_1_single ready\")\r\n",
    "\r\n",
    "nvsram2_1_half   = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/nvSRAM2/1/half/\")\r\n",
    "nvsram2_1_half.setup()\r\n",
    "nvsram2_1_half.createRuns()\r\n",
    "nvsram2_1_half.ignores = nvsram2_1_half.diffFinder(nvsram2_1_half.runs)\r\n",
    "print(\"nvsram2_1_half ready\")\r\n",
    "\r\n",
    "nvsram2_2_half   = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/nvSRAM2/2/half/\")\r\n",
    "nvsram2_2_half.setup()\r\n",
    "nvsram2_2_half.createRuns()\r\n",
    "nvsram2_2_half.ignores = nvsram2_2_half.diffFinder(nvsram2_2_half.runs)\r\n",
    "print(\"nvsram2_2_half ready\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sram3_1_single ready\n",
      "sram3_1_half ready\n",
      "sram3_2_half ready\n",
      "nvsram2_1_single ready\n",
      "nvsram2_1_half ready\n",
      "nvsram2_2_half ready\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "sram3_1_single_runs_ranked = []\r\n",
    "sram3_1_half_runs_ranked   = []\r\n",
    "sram3_2_half_ranked        = []\r\n",
    "nvsram2_1_single_ranked    = []\r\n",
    "nvsram2_1_half_ranked      = []\r\n",
    "nvsram2_2_half_ranked      = []\r\n",
    "\r\n",
    "for run in sram3_1_single.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        sram3_1_single_runs_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        sram3_1_half_runs_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in sram3_2_half.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        sram3_2_half_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in nvsram2_1_single.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        nvsram2_1_single_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in nvsram2_1_half.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        nvsram2_1_half_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "for run in nvsram2_2_half.runs.values():\r\n",
    "    if run.valid and run.errors:\r\n",
    "        nvsram2_2_half_ranked.append((run.num, run.errors))\r\n",
    "\r\n",
    "sram3_1_single_runs_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "sram3_1_half_runs_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "sram3_2_half_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "nvsram2_1_single_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "nvsram2_1_half_ranked.sort(reverse=True, key=lambda i: i[1])\r\n",
    "nvsram2_2_half_ranked.sort(reverse=True, key=lambda i: i[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the number of flipped bits per neutron event across the current data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "goldbyte = 170\r\n",
    "\r\n",
    "def hamDistFinder(error, goldbyte):\r\n",
    "    return bin(int(error[0], 16) ^ goldbyte).count('1')\r\n",
    "\r\n",
    "hamDistList_sub1 = []\r\n",
    "hamDistDict_sub1 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 0.1:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_sub1.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_sub1.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_sub1.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_sub1.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_sub1.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_sub1 = Counter(hamDistList_sub1)\r\n",
    "counts_sub1 = list(hamDistDict_sub1.values())\r\n",
    "tot_err_sub1 = sum(counts_sub1)\r\n",
    "x_sub1 = [0,1,2,3]\r\n",
    "lmbda_sub1 = 0.27\r\n",
    "poisson_sub1 = poisson.pmf(x_sub1, lmbda_sub1)\r\n",
    "errors_sub1 = [(math.sqrt(counts_sub1[0])), (math.sqrt(counts_sub1[1])),\r\n",
    "               (math.sqrt(counts_sub1[2]))]\r\n",
    "\r\n",
    "hamDistList_1 = []\r\n",
    "hamDistDict_1 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 1:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_1.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_1.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_1.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_1.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_1.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_1 = Counter(hamDistList_1)\r\n",
    "counts_1 = list(hamDistDict_1.values())\r\n",
    "tot_err_1 = sum(counts_1)\r\n",
    "x_1 = [0,1,2,3]\r\n",
    "lmbda_1 = 0.279\r\n",
    "poisson_1 = poisson.pmf(x_1, lmbda_1)\r\n",
    "errors_1 = [(math.sqrt(counts_1[0])), (math.sqrt(counts_1[1])),\r\n",
    "               (math.sqrt(counts_1[2]))]\r\n",
    "\r\n",
    "hamDistList_10 = []\r\n",
    "hamDistDict_10 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 10:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_10.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_10.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_10.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_10.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_10.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_10 = Counter(hamDistList_10)\r\n",
    "counts_10 = list(hamDistDict_10.values())\r\n",
    "tot_err_10 = sum(counts_10)\r\n",
    "x_10 = [0,1,2,3]\r\n",
    "lmbda_10 = 0.36\r\n",
    "poisson_10 = poisson.pmf(x_10, lmbda_10)\r\n",
    "errors_10 = [(math.sqrt(counts_10[0])), (math.sqrt(counts_10[1])),\r\n",
    "               (math.sqrt(counts_10[2]))]\r\n",
    "\r\n",
    "hamDistList_100 = []\r\n",
    "hamDistDict_100 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 100:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_100.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_100.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_100.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_100.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_100.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_100 = Counter(hamDistList_100)\r\n",
    "counts_100 = list(hamDistDict_100.values())\r\n",
    "tot_err_100 = sum(counts_100)\r\n",
    "x_100 = [0,1,2,3]\r\n",
    "lmbda_100 = 0.29\r\n",
    "poisson_100 = poisson.pmf(x_100, lmbda_100)\r\n",
    "errors_100 = [(math.sqrt(counts_100[0])), (math.sqrt(counts_100[1])),\r\n",
    "               (math.sqrt(counts_100[2]))]\r\n",
    "\r\n",
    "hamDistList_1000 = []\r\n",
    "hamDistDict_1000 = {}\r\n",
    "num_runs = 0\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            if run.delay == 1000:\r\n",
    "                for error in run.aErrNVRAM:\r\n",
    "                    hamDistList_1000.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.bErrNVRAM:\r\n",
    "                    hamDistList_1000.append(hamDistFinder(error, goldbyte))\r\n",
    "                for error in run.cErrNVRAM:\r\n",
    "                    hamDistList_1000.append(hamDistFinder(error, goldbyte))           \r\n",
    "                for error in run.dErrNVRAM:\r\n",
    "                    hamDistList_1000.append(hamDistFinder(error, goldbyte))\r\n",
    "            else:\r\n",
    "                hamDistList_1000.append(0)\r\n",
    "            num_runs += 1\r\n",
    "hamDistDict_1000 = Counter(hamDistList_1000)\r\n",
    "counts_1000 = list(hamDistDict_1000.values())\r\n",
    "tot_err_1000 = sum(counts_1000)\r\n",
    "x_1000 = [0,1,2,3]\r\n",
    "lmbda_1000 = 0.27\r\n",
    "poisson_1000 = poisson.pmf(x_1000, lmbda_1000)\r\n",
    "errors_1000 = [(math.sqrt(counts_1000[0])), (math.sqrt(counts_1000[1])),\r\n",
    "               (math.sqrt(counts_1000[2]))]\r\n",
    "\r\n",
    "# fig, ax = plt.subplots(1, 1)\r\n",
    "# ax.set(xlabel='Bit-flips', ylabel='Counts', ylim=(0,(0.9*tot_err)))\r\n",
    "# ax.bar(hamDistDict_sub1.keys(), hamDistDict_sub1.values(),\r\n",
    "#         label='Experimental data',\r\n",
    "#         color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "#         edgecolor='black',\r\n",
    "#         yerr=errors,\r\n",
    "#         align='center',\r\n",
    "#         ecolor='black',\r\n",
    "#         capsize=2)\r\n",
    "# plt.title(\"Histogram of observed memory errors\")\r\n",
    "# ax2 = ax.twinx()\r\n",
    "# ax2.set(ylabel='Probability of bit-flip', ylim=(0,0.9))\r\n",
    "# plt2 = ax2.plot(x, poisson_pd, 'k-',\r\n",
    "#                 label=f'Poisson distribution, $\\lambda$ = {lmbda}')\r\n",
    "# h1, l1 = ax.get_legend_handles_labels()\r\n",
    "# h2, l2 = ax2.get_legend_handles_labels()\r\n",
    "# ax.legend(h1+h2, l1+l2)\r\n",
    "\r\n",
    "# plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig2 = plt.figure()\r\n",
    "gs0 = gridspec.GridSpec(2, 3, figure=fig2, wspace=0.1)\r\n",
    "rc('xtick', labelsize=8)\r\n",
    "rc('ytick', labelsize=8)\r\n",
    "\r\n",
    "f2_ax1 = fig2.add_subplot(gs0[0, 0])\r\n",
    "f2_ax1.set(ylim=(0,(0.9*tot_err_sub1)))\r\n",
    "f2_ax1.bar(hamDistDict_sub1.keys(), hamDistDict_sub1.values(),\r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_sub1,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax1.margins(0,0)\r\n",
    "f2_ax1.xaxis.set_ticklabels([])\r\n",
    "f2_ax1_2 = f2_ax1.twinx()\r\n",
    "f2_ax1_2.set(ylim=(0,0.9))\r\n",
    "f2_ax1_2.plot(x_sub1, poisson_sub1, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_sub1}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax1_2.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax1_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_sub1}', ha='center', va='center')\r\n",
    "     \r\n",
    "f2_ax2 = fig2.add_subplot(gs0[1, 0])\r\n",
    "f2_ax2.set(ylim=(0,(0.9*tot_err_1)))\r\n",
    "f2_ax2.bar(hamDistDict_1.keys(), hamDistDict_1.values(),\r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_1,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax2.margins(0,0)\r\n",
    "f2_ax2.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
    "f2_ax2_2 = f2_ax2.twinx()\r\n",
    "f2_ax2_2.set(ylim=(0,0.9))\r\n",
    "f2_ax2_2.plot(x_1, poisson_1, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_1}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax2_2.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax2_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_1}', ha='center', va='center')\r\n",
    "\r\n",
    "f2_ax3 = fig2.add_subplot(gs0[0, 1])\r\n",
    "f2_ax3.set(ylim=(0,(0.9*tot_err_10)))\r\n",
    "f2_ax3.bar(hamDistDict_10.keys(), hamDistDict_10.values(), \r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_10,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax3.margins(0,0)\r\n",
    "f2_ax3.xaxis.set_ticklabels([])\r\n",
    "f2_ax3_2 = f2_ax3.twinx()\r\n",
    "f2_ax3_2.set(ylim=(0,0.9))\r\n",
    "f2_ax3_2.plot(x_10, poisson_10, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_10}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax3_2.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax3.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax3_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_10}', ha='center', va='center')\r\n",
    "\r\n",
    "f2_ax4 = fig2.add_subplot(gs0[1, 1])\r\n",
    "f2_ax4.set(ylim=(0,(0.9*tot_err_100)))\r\n",
    "f2_ax4.bar(hamDistDict_100.keys(), hamDistDict_100.values(),\r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_100,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax4.margins(0,0)\r\n",
    "f2_ax4.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
    "f2_ax4_2 = f2_ax4.twinx()\r\n",
    "f2_ax4_2.set(ylim=(0,0.9))\r\n",
    "f2_ax4_2.plot(x_100, poisson_100, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_100}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax4.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax4_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_100}', ha='center', va='center')\r\n",
    "\r\n",
    "f2_ax5 = fig2.add_subplot(gs0[0, 2])\r\n",
    "f2_ax5.set(ylim=(0,(0.9*tot_err_1000)))\r\n",
    "f2_ax5.bar(hamDistDict_1000.keys(), hamDistDict_1000.values(),\r\n",
    "        label='Experimental data',\r\n",
    "        color=(0.1, 0.1, 0.1, 0.1),\r\n",
    "        edgecolor='black',\r\n",
    "        yerr=errors_1000,\r\n",
    "        align='center',\r\n",
    "        ecolor='black',\r\n",
    "        linewidth=0.5,\r\n",
    "        error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\r\n",
    "f2_ax5.margins(0,0)\r\n",
    "f2_ax5.xaxis.set_ticklabels([])\r\n",
    "f2_ax5_2 = f2_ax5.twinx()\r\n",
    "f2_ax5_2.set(ylim=(0,0.9))\r\n",
    "f2_ax5_2.plot(x_1000, poisson_1000, 'k-',\r\n",
    "                label=f'$\\lambda$ = {lmbda_1000}',\r\n",
    "                linewidth=0.5)\r\n",
    "f2_ax5.axes.get_yaxis().set_visible(False)\r\n",
    "f2_ax5_2.text(1.85, 0.75, f'$\\lambda$ = {lmbda_1000}', ha='center', va='center')\r\n",
    "\r\n",
    "h1, l1 = f2_ax1.get_legend_handles_labels()\r\n",
    "h2, l2 = f2_ax1_2.get_legend_handles_labels()\r\n",
    "l1 = ['Experimental \\ndata']\r\n",
    "l2 = ['Poisson \\ndistribution']\r\n",
    "plt.legend(h1+h2, l1+l2, bbox_to_anchor=(0, -0.8, 1.3, 0.5), prop={'size': 6})\r\n",
    "\r\n",
    "fig2.text(0.5, 0.92, 'Error Frequency', ha='center', fontsize='x-large')\r\n",
    "fig2.text(0.5, 0, 'Bit-flips', ha='center')\r\n",
    "fig2.text(0.01, 0.5, 'Counts', va='center', rotation='vertical')\r\n",
    "fig2.text(1, 0.5, 'Probability of bit-flips occurring', va='center', rotation='vertical')\r\n",
    "\r\n",
    "plt.subplots_adjust(hspace=.0)\r\n",
    "plt.savefig('../../graphs/poisson/fish.svg', format='svg', dpi=1200)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "may20_june16_fluence = 1683696000000\r\n",
    "seconds           = 2332800\r\n",
    "chipir_flux       = may20_june16_fluence / seconds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "sram3_1_half.runs[318].dErrNVRAM"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# TODO: For each run satisfying below conditions, total number of seconds of all runs x flux = fluence for that cross-sec.\r\n",
    "\r\n",
    "counter = 0\r\n",
    "for run in nvsram2_1_single.runs.values():\r\n",
    "    if run.num not in sram3_1_half.ignores:\r\n",
    "        if run.errors:\r\n",
    "            counter += run.errors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "counter / may20_june16_fluence"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.939314460567703e-13"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "68e83ffa79d15a4f3f363f7e2d730fba250349155b7434a2a310aead7dfd6146"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}