{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from collections import Counter\r\n",
    "from datetime import datetime, timedelta as td\r\n",
    "import math\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import sys\r\n",
    "\r\n",
    "dtf = datetime.strftime\r\n",
    "dtp = datetime.strptime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ExpLogHandler:\r\n",
    "    def __init__(self, log_names):\r\n",
    "        self.log_names = log_names\r\n",
    "        \r\n",
    "    def getData(self):\r\n",
    "        self.data = pd.read_csv(self.log_names[0], error_bad_lines=False)\r\n",
    "        for i in range(1, len(self.log_names)):\r\n",
    "            data_next   = pd.read_csv(self.log_names[i], error_bad_lines=False)\r\n",
    "            data_frames = [self.data, data_next]\r\n",
    "            self.data   = pd.concat(data_frames, ignore_index=True)\r\n",
    "        self.data.drop(self.data.loc[(self.data[\"Timestamp\"] == \"Timestamp\")].index.tolist())\r\n",
    "        self.dataLength = self.data.shape[0]\r\n",
    "\r\n",
    "        wrchckbrdLocs  = self.data.loc[(self.data[\"Board\"] == \"M\") & (self.data[\"Mikroe_socket\"] == \"A\") &\r\n",
    "                                       (self.data[\"Status\"] == \"WRCHCKBRD\")].index.tolist()\r\n",
    "        wrchckbrdIndex = [(i, \"WRCHCKBRD\") for i in wrchckbrdLocs]\r\n",
    "        initLocs       = self.data.loc[(self.data[\"Board\"] == \"M\") & (self.data[\"Mikroe_socket\"] == \"A\") &\r\n",
    "                         (self.data[\"Status\"] == \"INIT\")].index.tolist()\r\n",
    "        initIndex      = [(i, \"INIT\") for i in initLocs]\r\n",
    "        runIndex       = wrchckbrdIndex + initIndex\r\n",
    "        runIndex       = sorted(runIndex)\r\n",
    "        runIndex.append((self.dataLength, \"END\"))\r\n",
    "        \r\n",
    "        runId  = 1\r\n",
    "        runCol = [''] * self.dataLength\r\n",
    "        for h in range(len(runIndex) - 1):\r\n",
    "            if runIndex[h][1] == \"WRCHCKBRD\":\r\n",
    "                start              = runIndex[h][0]\r\n",
    "                end                = runIndex[h+1][0]\r\n",
    "                runCol[start:end]  = [runId]*(end-start)\r\n",
    "                runId              += 1\r\n",
    "\r\n",
    "        self.data.insert(loc=0, column=\"Run_ID\", value=runCol)\r\n",
    "        return self.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class BeamLogHandler:\r\n",
    "    def __init__(self, firstTime, lastTime, targetDir_fullpathList):     \r\n",
    "        self.beamLogFnameFormat          = \"%Y-%m-%d\"\r\n",
    "        self.firstTime                   = firstTime\r\n",
    "        self.lastTime                    = lastTime\r\n",
    "        self.targetDir_fullpathList      = targetDir_fullpathList\r\n",
    "        self.targetDir_fullpathList[-4:] = [\"neutrons\"]\r\n",
    "\r\n",
    "    def getLogs(self):\r\n",
    "        firstBeamTime = dtf(self.firstTime, self.beamLogFnameFormat)\r\n",
    "        beamlogDayDif = (self.lastTime - self.firstTime).days\r\n",
    "        beamPath      = \"../../../neutrons/countlog-\"\r\n",
    "        self.beamlog  = pd.read_csv(f\"{beamPath}{firstBeamTime}.txt\",\r\n",
    "                        delim_whitespace=True, header=None, skiprows=1)\r\n",
    "        nextTime      = self.firstTime\r\n",
    "        for i in range(0, beamlogDayDif+1):\r\n",
    "            nextTime      = nextTime + td(days=1)\r\n",
    "            nextBeamTime  = dtf(nextTime, self.beamLogFnameFormat)\r\n",
    "            try:\r\n",
    "                nextBeamlog   = pd.read_csv(f\"{beamPath}{nextBeamTime}.txt\",delim_whitespace=True,header=None,skiprows=1)\r\n",
    "            except FileNotFoundError:\r\n",
    "                pass\r\n",
    "            beamlogFrames = [self.beamlog, nextBeamlog]\r\n",
    "            self.beamlog  = pd.concat(beamlogFrames, ignore_index=True)\r\n",
    "            \r\n",
    "        self.beamlog.columns = [\"Date\",\"HMS_time\",\"Millisecs\",\"Count1\",\"Count2\",\r\n",
    "                                \"Count3\",\"Count4\",\"protonCharge\",\"Beam_current\"]\r\n",
    "        return self.beamlog"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Run:\r\n",
    "    def __init__(self, num, runData):\r\n",
    "        self.delay     = -1\r\n",
    "        self.df        = runData\r\n",
    "        self.errors    = 0\r\n",
    "        self.fullErr   = -1\r\n",
    "        self.hot       = -1\r\n",
    "        self.num       = num\r\n",
    "        self.rowErr    = -1\r\n",
    "        self.see       = -1\r\n",
    "        self.valid     = -1\r\n",
    "        self.aErrorsNVRAM = []\r\n",
    "        self.bErrorsNVRAM = []\r\n",
    "        self.cErrorsNVRAM = []\r\n",
    "        self.dErrorsNVRAM = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Analyser:\r\n",
    "    def __init__(self, targetDir_fullpath):\r\n",
    "        self.targetDir_fullpath  = targetDir_fullpath\r\n",
    "        self.expLogTstampFormat  = \"%Y-%m-%d_%H-%M-%S-%f\"\r\n",
    "        self.beamLogTstampFormat = \"%d/%m/%Y %H:%M:%S\"\r\n",
    " \r\n",
    "    def setup(self):\r\n",
    "        targetDir_fullpathList = self.targetDir_fullpath.split(\"/\")\r\n",
    "        targetDir_trunc        = targetDir_fullpathList[-3:]\r\n",
    "        self.chip              = targetDir_trunc[0]\r\n",
    "        self.variant           = targetDir_trunc[1]\r\n",
    "        self.size              = targetDir_trunc[2]\r\n",
    "\r\n",
    "        # Get data from logs\r\n",
    "        self.log_names     = [self.targetDir_fullpath+i for i in os.listdir(self.targetDir_fullpath) if \".csv\" in i]\r\n",
    "        self.log_names.sort(key = lambda x: dtp(x, f\"{self.targetDir_fullpath}nvRAM_data_%d-%m-%Y-%H%M.csv\"))\r\n",
    "        self.ExpLogHandler = ExpLogHandler(self.log_names)\r\n",
    "        self.data          = self.ExpLogHandler.getData()\r\n",
    "\r\n",
    "        # Get beam status from logs\r\n",
    "        firstTimestamp      = self.data[0:1]['Timestamp'][0]\r\n",
    "        lastTimestamp       = self.data[self.data.shape[0]-2:self.data.shape[0]-1]['Timestamp'][self.data.shape[0]-2]\r\n",
    "        firstTime           = dtp(firstTimestamp, self.expLogTstampFormat)\r\n",
    "        lastTime            = dtp(lastTimestamp, self.expLogTstampFormat)\r\n",
    "        self.BeamLogHandler = BeamLogHandler(firstTime, lastTime, targetDir_fullpathList)\r\n",
    "        self.beamlog        = self.BeamLogHandler.getLogs()\r\n",
    "\r\n",
    "        # Create datetime objects from beamlog timestamps\r\n",
    "        beamlogTstamps    = (self.beamlog['Date']+self.beamlog['HMS_time']+self.beamlog['Millisecs'].apply(str)).tolist()\r\n",
    "        self.beamlogTimes = []\r\n",
    "        for i in beamlogTstamps:\r\n",
    "            if len(i) > 23:\r\n",
    "                i = i[0:26]\r\n",
    "            self.beamlogTimes.append(i)\r\n",
    "        self.beamlogTimes = [dtp(i, '%d/%m/%Y%H:%M:%S0.%f') for i in self.beamlogTimes]\r\n",
    "\r\n",
    "    def beamOn(self, firstTstamp, lastTstamp):\r\n",
    "        bOfirstTime = firstTstamp\r\n",
    "        bOlastTime = lastTstamp\r\n",
    "        beamTimeNearFirstTime = min([i for i in self.beamlogTimes if i <= bOfirstTime], key=lambda x: abs(x - bOfirstTime))\r\n",
    "        beamTimeNearLastTime  = min([i for i in self.beamlogTimes if i >= bOlastTime], key=lambda x: abs(x - bOlastTime))\r\n",
    "        firstRow              = self.beamlog.loc[(self.beamlog['Date'] == dtf(beamTimeNearFirstTime, '%d/%m/%Y')) &\r\n",
    "                                (self.beamlog['HMS_time'] == dtf(beamTimeNearFirstTime, '%H:%M:%S'))]\r\n",
    "        lastRow               = self.beamlog.loc[(self.beamlog['Date'] == dtf(beamTimeNearLastTime, '%d/%m/%Y')) & \r\n",
    "                                (self.beamlog['HMS_time'] == dtf(beamTimeNearLastTime, '%H:%M:%S'))]\r\n",
    "        count4Dif             = lastRow.iloc[0]['Count4'] - firstRow.iloc[0]['Count4']\r\n",
    "        numRows               = lastRow.index.astype(int)[0] - firstRow.index.astype(int)[0]\r\n",
    "        cps                   = count4Dif / numRows\r\n",
    "        if cps > 1:\r\n",
    "            return 1\r\n",
    "        return 0\r\n",
    "\r\n",
    "    def createRuns(self):\r\n",
    "        runNames  = []\r\n",
    "        self.runs = {}\r\n",
    "        lastRunID =  self.data[self.data['Run_ID'].last_valid_index():self.data['Run_ID']. \\\r\n",
    "                    last_valid_index()+1]['Run_ID'][self.data['Run_ID'].last_valid_index()]\r\n",
    "\r\n",
    "        # Supply Run initialiser with truncated data \r\n",
    "        for i in range(1, lastRunID + 1):\r\n",
    "            runNames.append(f\"run_{i}\")\r\n",
    "            runData      = self.data.loc[(self.data[\"Run_ID\"] == i)]\r\n",
    "            runData.reset_index(inplace=True, drop=True)\r\n",
    "            self.runs[i] = Run(i, runData)\r\n",
    "\r\n",
    "        for run in self.runs.values():\r\n",
    "            try:\r\n",
    "                # Extract beam delay from timestamps\r\n",
    "                before_delay_i  = run.df.loc[(run.df['Mikroe_socket']=='D') & (run.df['Status']=='STORE_OK')].index[0]\r\n",
    "                before_delay_t  = run.df.loc[before_delay_i]['Timestamp']\r\n",
    "                after_delay_i   = run.df.loc[(run.df['Mikroe_socket']=='A') & (run.df['Status']=='VERIF')].index[0]+1\r\n",
    "                after_delay_t   = run.df.loc[after_delay_i]['Timestamp']\r\n",
    "                before_delay_dt = dtp(before_delay_t, self.expLogTstampFormat)\r\n",
    "                after_delay_dt  = dtp(after_delay_t, self.expLogTstampFormat)   \r\n",
    "                dif             = after_delay_dt - before_delay_dt\r\n",
    "                if td(seconds = 0.1) < dif < td(seconds = 0.5):\r\n",
    "                    run.delay = 0.1\r\n",
    "                if td(seconds = 0.5) < dif < td(seconds = 5):\r\n",
    "                    run.delay = 1\r\n",
    "                if td(seconds = 5) < dif < td(seconds = 50):\r\n",
    "                    run.delay = 10\r\n",
    "                if td(seconds = 50) < dif < td(seconds = 500):\r\n",
    "                    run.delay = 100\r\n",
    "                if td(seconds = 500) < dif < td(seconds = 5000):\r\n",
    "                    run.delay = 1000\r\n",
    "\r\n",
    "                # Was the beam on?\r\n",
    "                try:\r\n",
    "                    if self.beamOn(before_delay_dt, after_delay_dt):\r\n",
    "                        run.hot = 1\r\n",
    "                    else:\r\n",
    "                        run.hot = 0\r\n",
    "                except ValueError:\r\n",
    "                    print(run.name)\r\n",
    "\r\n",
    "                # Create list of errors in nvRAM per chip\r\n",
    "                aErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                       (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                        run.df.loc[(run.df[\"Mikroe_socket\"] == \"A\") & \r\n",
    "                                       (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                bErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") & \r\n",
    "                                       (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                        run.df.loc[(run.df[\"Mikroe_socket\"] == \"B\") &\r\n",
    "                                       (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                cErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                       (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                        run.df.loc[(run.df[\"Mikroe_socket\"] == \"C\") & \r\n",
    "                                       (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                dErrorBounds = list(zip(run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                       (run.df[\"Status\"] == \"VERIF\")].index.tolist(),\r\n",
    "                                        run.df.loc[(run.df[\"Mikroe_socket\"] == \"D\") & \r\n",
    "                                       (run.df[\"Status\"] == \"VERIF_OK\")].index.tolist()))\r\n",
    "\r\n",
    "                aErrorsBefRec = list(zip(run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                         run.df[aErrorBounds[0][0]+1:aErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                aErrorsAftRec = list(zip(run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                         run.df[aErrorBounds[1][0]+1:aErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                bErrorsBefRec = list(zip(run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                         run.df[bErrorBounds[0][0]+1:bErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                bErrorsAftRec = list(zip(run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                         run.df[bErrorBounds[1][0]+1:bErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                cErrorsBefRec = list(zip(run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                         run.df[cErrorBounds[0][0]+1:cErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                cErrorsAftRec = list(zip(run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                         run.df[cErrorBounds[1][0]+1:cErrorBounds[1][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "\r\n",
    "                dErrorsBefRec = list(zip(run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                         run.df[dErrorBounds[0][0]+1:dErrorBounds[0][1]][\"SDC_loc\"].values.tolist()))\r\n",
    "                dErrorsAftRec = list(zip(run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_val\"].values.tolist(),\r\n",
    "                                         run.df[dErrorBounds[1][0]+1:dErrorBounds[1][1]][\"SDC_loc\"].values.tolist())) \r\n",
    "                \r\n",
    "                run.aErrorsNVRAM = [i for i in aErrorsAftRec if i not in aErrorsBefRec if np.nan not in i]\r\n",
    "                run.bErrorsNVRAM = [i for i in bErrorsAftRec if i not in bErrorsBefRec if np.nan not in i]\r\n",
    "                run.cErrorsNVRAM = [i for i in cErrorsAftRec if i not in cErrorsBefRec if np.nan not in i]\r\n",
    "                run.dErrorsNVRAM = [i for i in dErrorsAftRec if i not in dErrorsBefRec if np.nan not in i]\r\n",
    "\r\n",
    "                run.errors += len(run.aErrorsNVRAM)\r\n",
    "                run.errors += len(run.bErrorsNVRAM)\r\n",
    "                run.errors += len(run.cErrorsNVRAM)\r\n",
    "                run.errors += len(run.dErrorsNVRAM)\r\n",
    "\r\n",
    "            # Invalidate run if critical experiment steps didn't occur\r\n",
    "            except IndexError:\r\n",
    "                run.valid = 0\r\n",
    "            else:\r\n",
    "                run.valid = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sram3_1_half = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/SRAM3/1/half/\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sram3_1_half.setup()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sram3_1_half.createRuns()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Need to deal with runs where experiment restarts during it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finding runs with nvRAM errors:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "runs_with_err = []\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.errors:\r\n",
    "        runs_with_err.append(run.num)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "runs_with_nvram_err = []\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "        if run.aErrorsNVRAM:\r\n",
    "            runs_with_nvram_err.append(run.num)\r\n",
    "        elif run.bErrorsNVRAM:\r\n",
    "            runs_with_nvram_err.append(run.num)\r\n",
    "        elif run.cErrorsNVRAM:\r\n",
    "            runs_with_nvram_err.append(run.num)\r\n",
    "        elif run.dErrorsNVRAM:\r\n",
    "            runs_with_nvram_err.append(run.num)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(runs_with_nvram_err)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sram3_1_half.runs[466].errors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sram3_1_half.runs[466].dErrorsNVRAM"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "runErrorsRanked = []\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.errors:\r\n",
    "        runErrorsRanked.append((run.num, run.errors))\r\n",
    "\r\n",
    "runErrorsRanked.sort(reverse=True, key=lambda i: i[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the number of flipped bits per neutron event across the current data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "goldbyte = 170\r\n",
    "hamDistList = []\r\n",
    "ignores = [1593, 1512, 1547, 27, 455]\r\n",
    "for run in sram3_1_half.runs.values():\r\n",
    "    if run.num not in ignores:\r\n",
    "        if run.errors:\r\n",
    "            for error in run.aErrorsNVRAM:\r\n",
    "                hamDist = bin(int(error[0], 16) ^ goldbyte).count('1')\r\n",
    "                hamDistList.append(hamDist)\r\n",
    "\r\n",
    "hamDistDict = Counter(hamDistList)\r\n",
    "plt.bar(hamDistDict.keys(), hamDistDict.values())\r\n",
    "plt.title(\"Number of flipped bits per neutron event\")\r\n",
    "plt.xlabel(\"Flipped bits\")\r\n",
    "plt.ylabel(\"Single event effects\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "68e83ffa79d15a4f3f363f7e2d730fba250349155b7434a2a310aead7dfd6146"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}