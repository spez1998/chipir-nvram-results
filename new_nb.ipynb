{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from datetime import datetime, timedelta as td\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import sys\r\n",
    "\r\n",
    "dtf = datetime.strftime\r\n",
    "dtp = datetime.strptime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class ExpLogHandler:\r\n",
    "    def __init__(self, log_names):\r\n",
    "        self.log_names = log_names\r\n",
    "        \r\n",
    "    def getData(self):\r\n",
    "        self.data = pd.read_csv(self.log_names[0], error_bad_lines=False)\r\n",
    "        for i in range(1, len(self.log_names)):\r\n",
    "            data_next   = pd.read_csv(self.log_names[i], error_bad_lines=False)\r\n",
    "            data_frames = [self.data, data_next]\r\n",
    "            self.data   = pd.concat(data_frames, ignore_index=True)\r\n",
    "        self.data.drop(self.data.loc[(self.data[\"Timestamp\"] == \"Timestamp\")].index.tolist())\r\n",
    "        self.dataLength = self.data.shape[0]\r\n",
    "\r\n",
    "        wrchckbrdLocs  = self.data.loc[(self.data[\"Board\"] == \"M\") & (self.data[\"Mikroe_socket\"] == \"A\") &\r\n",
    "                                       (self.data[\"Status\"] == \"WRCHCKBRD\")].index.tolist()\r\n",
    "        wrchckbrdIndex = [(i, \"WRCHCKBRD\") for i in wrchckbrdLocs]\r\n",
    "        initLocs       = self.data.loc[(self.data[\"Board\"] == \"M\") & (self.data[\"Mikroe_socket\"] == \"A\") &\r\n",
    "                         (self.data[\"Status\"] == \"INIT\")].index.tolist()\r\n",
    "        initIndex      = [(i, \"INIT\") for i in initLocs]\r\n",
    "        runIndex       = wrchckbrdIndex + initIndex\r\n",
    "        runIndex       = sorted(runIndex)\r\n",
    "        runIndex.append((self.dataLength, \"END\"))\r\n",
    "        \r\n",
    "        runId  = 1\r\n",
    "        runCol = [''] * self.dataLength\r\n",
    "        for h in range(len(runIndex) - 1):\r\n",
    "            if runIndex[h][1] == \"WRCHCKBRD\":\r\n",
    "                start              = runIndex[h][0]\r\n",
    "                end                = runIndex[h+1][0]\r\n",
    "                runCol[start:end]  = [runId]*(end-start)\r\n",
    "                runId              += 1\r\n",
    "\r\n",
    "        self.data.insert(loc=0, column=\"Run_ID\", value=runCol)\r\n",
    "        return self.data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class BeamLogHandler:\r\n",
    "    def __init__(self, firstTime, lastTime, targetDir_fullpathList):     \r\n",
    "        self.beamLogFnameFormat          = \"%Y-%m-%d\"\r\n",
    "        self.firstTime                   = firstTime\r\n",
    "        self.lastTime                    = lastTime\r\n",
    "        self.targetDir_fullpathList      = targetDir_fullpathList\r\n",
    "        self.targetDir_fullpathList[-4:] = [\"neutrons\"]\r\n",
    "\r\n",
    "    def getLogs(self):\r\n",
    "        firstBeamTime = dtf(self.firstTime, self.beamLogFnameFormat)\r\n",
    "        beamlogDayDif = (self.lastTime - self.firstTime).days\r\n",
    "        beamPath      = \"../../../neutrons/countlog-\"\r\n",
    "        self.beamlog  = pd.read_csv(f\"{beamPath}{firstBeamTime}.txt\",\r\n",
    "                        delim_whitespace=True, header=None, skiprows=1)\r\n",
    "        nextTime      = self.firstTime\r\n",
    "        for i in range(0, beamlogDayDif+1):\r\n",
    "            nextTime      = nextTime + td(days=1)\r\n",
    "            nextBeamTime  = dtf(nextTime, self.beamLogFnameFormat)\r\n",
    "            nextBeamlog   = pd.read_csv(f\"{beamPath}{nextBeamTime}.txt\",delim_whitespace=True,header=None,skiprows=1)\r\n",
    "            beamlogFrames = [self.beamlog, nextBeamlog]\r\n",
    "            self.beamlog  = pd.concat(beamlogFrames, ignore_index=True)\r\n",
    "            \r\n",
    "        self.beamlog.columns = [\"Date\",\"HMS_time\",\"Millisecs\",\"Count1\",\"Count2\",\r\n",
    "                                \"Count3\",\"Count4\",\"protonCharge\",\"Beam_current\"]\r\n",
    "        return self.beamlog"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Run:\r\n",
    "    def __init__(self, name, data):\r\n",
    "        self.name   = name\r\n",
    "        self.valid  = -1\r\n",
    "        self.hot    = -1\r\n",
    "        self.delay  = -1\r\n",
    "        self.num    = [int(s) for s in name.split('_') if s.isdigit()][0]\r\n",
    "        self.df     = data.loc[(data['Run_ID'] == self.num)]\r\n",
    "        self.errors = -1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Analyser:\r\n",
    "    def __init__(self, targetDir_fullpath):\r\n",
    "        self.targetDir_fullpath  = targetDir_fullpath\r\n",
    "        self.expLogTstampFormat  = \"%Y-%m-%d_%H-%M-%S-%f\"\r\n",
    "        self.beamLogTstampFormat = \"%d/%m/%Y %H:%M:%S\"\r\n",
    " \r\n",
    "    def setup(self):\r\n",
    "        targetDir_fullpathList = self.targetDir_fullpath.split(\"/\")\r\n",
    "        targetDir_trunc        = targetDir_fullpathList[-3:]\r\n",
    "        self.chip              = targetDir_trunc[0]\r\n",
    "        self.variant           = targetDir_trunc[1]\r\n",
    "        self.size              = targetDir_trunc[2]\r\n",
    "\r\n",
    "        # Get data from logs\r\n",
    "        self.log_names     = [self.targetDir_fullpath+i for i in os.listdir(self.targetDir_fullpath) if \".csv\" in i]\r\n",
    "        self.log_names.sort(key=os.path.getmtime)\r\n",
    "        self.ExpLogHandler = ExpLogHandler(self.log_names)\r\n",
    "        self.data          = self.ExpLogHandler.getData()\r\n",
    "\r\n",
    "        # Get beam status from logs\r\n",
    "        firstTimestamp      = self.data[0:1]['Timestamp'][0]\r\n",
    "        lastTimestamp       = self.data[self.data.shape[0]-2:self.data.shape[0]-1]['Timestamp'][self.data.shape[0]-2]\r\n",
    "        firstTime           = dtp(firstTimestamp, self.expLogTstampFormat)\r\n",
    "        lastTime            = dtp(lastTimestamp, self.expLogTstampFormat)\r\n",
    "        self.BeamLogHandler = BeamLogHandler(firstTime, lastTime, targetDir_fullpathList)\r\n",
    "        self.beamlog        = self.BeamLogHandler.getLogs()\r\n",
    "\r\n",
    "        # Create datetime objects from beamlog timestamps\r\n",
    "        beamlogTstamps    = (self.beamlog['Date']+self.beamlog['HMS_time']+self.beamlog['Millisecs'].apply(str)).tolist()\r\n",
    "        self.beamlogTimes = []\r\n",
    "        for i in beamlogTstamps:\r\n",
    "            if len(i) > 23:\r\n",
    "                i = i[0:26]\r\n",
    "            self.beamlogTimes.append(i)\r\n",
    "        self.beamlogTimes = [dtp(i, '%d/%m/%Y%H:%M:%S0.%f') for i in self.beamlogTimes]\r\n",
    "\r\n",
    "    def beamOn(self, firstTstamp, lastTstamp):\r\n",
    "        bOfirstTime = firstTstamp\r\n",
    "        bOlastTime = lastTstamp\r\n",
    "        beamTimeNearFirstTime = min([i for i in self.beamlogTimes if i <= bOfirstTime], key=lambda x: abs(x - bOfirstTime))\r\n",
    "        beamTimeNearLastTime  = min([i for i in self.beamlogTimes if i >= bOlastTime], key=lambda x: abs(x - bOlastTime))\r\n",
    "        firstRow              = self.beamlog.loc[(self.beamlog['Date'] == dtf(beamTimeNearFirstTime, '%d/%m/%Y')) &\r\n",
    "                                (self.beamlog['HMS_time'] == dtf(beamTimeNearFirstTime, '%H:%M:%S'))]\r\n",
    "        lastRow               = self.beamlog.loc[(self.beamlog['Date'] == dtf(beamTimeNearLastTime, '%d/%m/%Y')) & \r\n",
    "                                (self.beamlog['HMS_time'] == dtf(beamTimeNearLastTime, '%H:%M:%S'))]\r\n",
    "        count4Dif             = lastRow.iloc[0]['Count4'] - firstRow.iloc[0]['Count4']\r\n",
    "        numRows               = lastRow.index.astype(int)[0] - firstRow.index.astype(int)[0]\r\n",
    "        cps                   = count4Dif / numRows\r\n",
    "        if cps > 1:\r\n",
    "            return 1\r\n",
    "        return 0\r\n",
    " \r\n",
    "    def createRuns(self):\r\n",
    "        runNames  = []\r\n",
    "        self.runs = {}\r\n",
    "        for i in range(1, self.data[self.data['Run_ID'].last_valid_index(): \\\r\n",
    "                          self.data['Run_ID'].last_valid_index()+1]['Run_ID'][self.data['Run_ID'].last_valid_index()]+1):\r\n",
    "            runNames.append(f\"run_{i}\")\r\n",
    "        for i in runNames:\r\n",
    "            self.runs[i] = Run(i, self.data)\r\n",
    "\r\n",
    "    def processRuns(self): \r\n",
    "        for value in self.runs.values():\r\n",
    "            try:\r\n",
    "                before_delay_i  = value.df.loc[(value.df['Mikroe_socket']=='D') & (value.df['Status']=='STORE_OK')].index[0]\r\n",
    "                before_delay_t  = value.df.loc[[before_delay_i]['Timestamp'] & (value.df['Status']=='VERIF')].index[0]+1\r\n",
    "                after_delay_i   = value.df.loc[(value.df['Mikroe_socket']=='A') & (value.df['Status']=='VERIF')].index[0]+1\r\n",
    "                after_delay_t   = value.df.loc[after_delay_i]['Timestamp']\r\n",
    "                before_delay_dt = dtp(before_delay_t, self.expLogTstampFormat)\r\n",
    "                after_delay_dt  = dtp(after_delay_t, self.expLogTstampFormat)   \r\n",
    "                dif             = after_delay_dt - before_delay_dt\r\n",
    "                if td(seconds = 0.1) < dif < td(seconds = 0.5):\r\n",
    "                    value.delay = 0.1\r\n",
    "                if td(seconds = 0.5) < dif < td(seconds = 5):\r\n",
    "                    value.delay = 1\r\n",
    "                if td(seconds = 5) < dif < td(seconds = 50):\r\n",
    "                    value.delay = 10\r\n",
    "                if td(seconds = 50) < dif < td(seconds = 500):\r\n",
    "                    value.delay = 100\r\n",
    "                if td(seconds = 500) < dif < td(seconds = 5000):\r\n",
    "                    value.delay = 1000\r\n",
    "\r\n",
    "                try:\r\n",
    "                    if self.beamOn(before_delay_dt, after_delay_dt):\r\n",
    "                        value.hot = 1\r\n",
    "                    else:\r\n",
    "                        value.hot = 0\r\n",
    "                except ValueError:\r\n",
    "                    print(value.name)\r\n",
    "                    \r\n",
    "                try:\r\n",
    "                    value.errors = value.df['Status'].value_counts()['SDC']\r\n",
    "                except KeyError:\r\n",
    "                    value.errors = 0\r\n",
    "\r\n",
    "            except IndexError:\r\n",
    "                value.valid = 0\r\n",
    "            else:\r\n",
    "                value.valid = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "sram3_1_half = Analyser(\"C:/Users/Sujit/Documents/STFC/Code/Mikroe/nvRAM_experiment/results/live/SRAM3/1/half/123456789012\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "sram3_1_half.setup()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "sram3_1_half.createRuns()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "sram3_1_half.processRuns()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "68e83ffa79d15a4f3f363f7e2d730fba250349155b7434a2a310aead7dfd6146"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}